<!DOCTYPE html>
<html lang="en" xmlns:p="http://www.w3.org/1999/html">
<head>
  <meta charset="utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Alpenglow Plan &amp; Documentation</title>

  <link rel="shortcut icon" type="image/x-icon" href="../../scenery/assets/logo-v1.svg">
  <link rel="stylesheet" href="../../sherpa/lib/bootstrap-2.2.2.css">
  <link rel="stylesheet" href="../../sherpa/lib/bootstrap-responsive-2.2.2.css">

  <script>
    window.MathJax = {
      tex: {
        inlineMath: [ [ '$', '$' ], [ '\\(', '\\)' ] ]
      },
      autoload: {
        cases: [ [], [ 'numcases', 'subnumcases' ] ]
      }
    };
  </script>
  <script id="MathJax-script" async src="../../sherpa/mathjax/tex-chtml.js"></script>

  <script>
    window.phet = window.phet || {};

    window.pendingDiagrams = [];
    window.addDiagram = ( id, callback ) => {
      window.pendingDiagrams.push( { id: id, callback: callback } );
    };
  </script>

  <!-- Before loading other things (that might error), create hooks to report errors/loads for continuous testing -->
  <script src="../../chipper/js/sim-tests/pageload-connector.js"></script>

  <!-- jQuery and LoDash are dependencies -->
  <script src="../../sherpa/lib/jquery-2.1.0.min.js"></script>
  <script src="../../sherpa/lib/lodash-4.17.4.min.js"></script>

  <script src="../../assert/js/assert.js"></script>
  <script src="../../tandem/js/PhetioIDUtils.js"></script>
  <script src="../../sherpa/lib/linebreak-1.1.0.js"></script>
  <script src="../../sherpa/lib/flatqueue-1.2.1.js"></script>
  <script src="../../sherpa/lib/paper-js-0.12.17.js"></script>
  <script src="../../sherpa/lib/he-1.1.1.js"></script>
  <script src="../../sherpa/lib/TextEncoderLite-3c9f6f0.js"></script>
  <script src="../../sherpa/lib/base64-js-1.2.0.js"></script>

  <script type="text/javascript">
    // window.assertions.enableAssert();
    // window.assertions.enableAssertSlow();
  </script>

  <!-- For the styling -->
  <script src="../../sherpa/lib/bootstrap-2.2.2.js"></script>

  <link rel="stylesheet" href="../../sherpa/lib/codemirror-5.52.2.min.css">
  <link rel="stylesheet" href="../../sherpa/lib/codemirror-5.52.2.monokai.min.css">

  <script src="../../sherpa/lib/codemirror-5.52.2.min.js"></script>
  <script src="../../sherpa/lib/codemirror-5.52.2.javascript.min.js"></script>

  <script src="../../scenery/doc/extractFunctionJS.js"></script>

  <script src="./teapotObj.js"></script>

  <style>
    .CodeMirror {
      height: auto;
      border-radius: 5px;
      margin-top: 10px;
      margin-bottom: 10px;
      text-align: left;
    }

    .errors {
      border: 1px solid red;
    }

    .TODO::before {
      content: "TODO: ";
      font-weight: bold;
    }

    .TODO {
      color: red;
    }

    .DEFERRED::before {
      content: "Deferred: ";
      font-weight: bold;
    }

    .DEFERRED {
      color: green;
    }

    .example {
      margin: 0 auto;
      text-align: center;
    }

    .nav-list {
      padding-left: 8px;
      padding-right: 0px;
    }

    .nav-list li {
      line-height: 10px;
      font-size: 90%;
    }

    pre.mermaid {
      margin: 0 auto;
      background-color: transparent;
      border: none;
    }

    pre.mermaid span {
      text-shadow: none;
    }
  </style>
</head>

<body>

<script type="module">
  import '../../chipper/dist/js/scenery/js/main.js';
  import '../../chipper/dist/js/alpenglow/js/main.js';
  import '../../chipper/dist/js/phet-core/js/main.js';
  import '../../chipper/dist/js/axon/js/main.js';
  import '../../chipper/dist/js/dot/js/main.js';
  import '../../chipper/dist/js/kite/js/main.js';
  import '../../chipper/dist/js/utterance-queue/js/main.js';

  phet.scenery.Utils.polyfillRequestAnimationFrame();
</script>

<script type="module">

  // TODO: move to a standalone JS file!

  import { Node, Display } from '../../chipper/dist/js/scenery/js/imports.js';
  import { CombinedRaster, Rasterize } from '../../chipper/dist/js/alpenglow/js/imports.js';
  import Bounds2 from '../../chipper/dist/js/dot/js/Bounds2.js';
  import Matrix3 from '../../chipper/dist/js/dot/js/Matrix3.js';
  // import dot from '../../chipper/dist/js/dot/js/dot.js';
  // const v2 = dot.v2;
  // const v3 = dot.v3;
  // const v4 = dot.v4;
  //
  // const colors = [
  //   new Color( 62, 171, 3 ),
  //   new Color( 23, 180, 77 ),
  //   new Color( 24, 183, 138 ),
  //   new Color( 23, 178, 194 ),
  //   new Color( 20, 163, 238 ),
  //   new Color( 71, 136, 255 ),
  //   new Color( 171, 101, 255 ),
  //   new Color( 228, 72, 235 ),
  //   new Color( 252, 66, 186 ),
  //   new Color( 252, 82, 127 )
  // ];

  window.deviceContextPromise = phet.alpenglow.DeviceContext.getDevice().then( device => {
    if ( device ) {
      return new phet.alpenglow.DeviceContext( device );
    }
    else {
      return null;
    }
  } );

  window.piecewiseOptions = {
    minLevels: 1,
    maxLevels: 10,
    // distanceEpsilon: 0.02,
    distanceEpsilon: 0.0002,
    curveEpsilon: 0.2
  };
  window.shapeToPolygons = shape => shape.subpaths.map( subpath => {
    return subpath.toPiecewiseLinear( window.piecewiseOptions ).segments.map( line => {
      return line.start;
    } );
  } );

  window.diagramFont = new phet.scenery.Font( {
    size: 12,
    family: 'Arial, sans-serif'
  } );

  window.sizeCanvas = canvas => {
    canvas.style.width = `${canvas.width / window.devicePixelRatio}px`;
    canvas.style.height = `${canvas.height / window.devicePixelRatio}px`;
  };

  window.getSceneryElement = ( node, width, height, background, renderer ) => {
    const subdiv = document.createElement( 'div' );
    subdiv.style.margin = '0 auto';
    const scene = new Node( { renderer: renderer } );
    const display = new Display( scene, {
      width: width,
      height: height,
      accessibility: true,
      container: subdiv,
      allowCSSHacks: false
    } );

    display.width = width;
    display.height = height;
    scene.addChild( node );
    display.backgroundColor = background;
    display.updateDisplay();
    scene.removeChild( node );
    return subdiv;
  };

  // composite Rasterize/CombinedRaster options
  window.getRasterizedElement = ( renderProgram, width, height, options ) => {
    const program = renderProgram.transformed( Matrix3.scaling( window.devicePixelRatio ) );

    const outputWidth = width * window.devicePixelRatio;
    const outputHeight = height * window.devicePixelRatio;

    const raster = new CombinedRaster( outputWidth, outputHeight, options );
    Rasterize.rasterize( program, raster, new Bounds2( 0, 0, outputWidth, outputHeight ), options );
    const canvas = Rasterize.imageDataToCanvas( raster.toImageData() );
    window.sizeCanvas( canvas );
    canvas.style.display = 'block';
    canvas.style.position = 'relative';
    canvas.style.margin = '0 auto';
    canvas.style.left = '0';
    canvas.style.top = '0';
    return canvas;
  };

  window.createRenderProgramSandbox = ( id, func, width, height, providedOptions ) => {

    const { js, jsBefore, jsAfter } = window.extractFunctionJS( func );

    const options = phet.phetCore.merge( {
      jsBefore: jsBefore,
      jsAfter: jsAfter,
      showInstructions: false
    }, providedOptions );

    const parentElement = document.getElementById( id );

    const displayContainerElement = document.createElement( 'div' );
    !options.showInstructions && parentElement.appendChild( displayContainerElement );

    const codeContainerElement = document.createElement( 'div' );
    parentElement.appendChild( codeContainerElement );
    options.showInstructions && parentElement.appendChild( displayContainerElement );

    const errorsContainerElement = document.createElement( 'div' );
    parentElement.appendChild( errorsContainerElement );
    errorsContainerElement.classList.add( 'errors' );

    const codeMirror = CodeMirror( codeContainerElement, { // eslint-disable-line no-undef
      lineNumbers: true,
      tabSize: 2,
      value: js,
      mode: 'javascript',
      theme: 'monokai',
      lineWrapping: true
    } );

    const isDescendant = function( parent, child ) {
      let node = child;
      while ( node ) {
        if ( node === parent ) {
          return true;
        }

        // Traverse up to the parent
        node = node.parentNode;
      }

      // Go up until the root but couldn't find the `parent`
      return false;
    };

    window.addEventListener( 'keydown', event => {
      // if shift-enter is pressed
      if ( event.keyCode === 13 && event.shiftKey && isDescendant( document.getElementById( 'code' ), document.activeElement ) ) {
        run();

        event.preventDefault();
      }
    } );

    const run = async () => {


      displayContainerElement.style.backgroundColor = 'transparent';
      errorsContainerElement.style.display = 'none';

      try {
        const code = `
        ${Math.random()};
        let value = (${options.jsBefore}
          const dot = phet.dot;
          const alpenglow = phet.alpenglow;
          const v2 = dot.v2;
          const v3 = dot.v3;
          const v4 = dot.v4;
          const Bounds2 = dot.Bounds2;
          const Matrix3 = dot.Matrix3;
          const Vector2 = dot.Vector2;
          const Vector3 = dot.Vector3;
          const Vector4 = dot.Vector4;
          const RenderBlendType = alpenglow.RenderBlendType;
          const RenderComposeType = alpenglow.RenderComposeType;
          const RenderExtend = alpenglow.RenderExtend;
          const RenderProgram = alpenglow.RenderProgram;
          const RenderPath = alpenglow.RenderPath;
          const RenderPathBoolean = alpenglow.RenderPathBoolean;
          const RenderColor = alpenglow.RenderColor;
          const RenderColorSpace = alpenglow.RenderColorSpace;
          const RenderColorSpaceConversion = alpenglow.RenderColorSpaceConversion;
          const RenderAlpha = alpenglow.RenderAlpha;
          const RenderNormalize = alpenglow.RenderNormalize;
          const RenderPremultiply = alpenglow.RenderPremultiply;
          const RenderUnpremultiply = alpenglow.RenderUnpremultiply;
          const RenderSRGBToLinearSRGB = alpenglow.RenderSRGBToLinearSRGB;
          const RenderLinearSRGBToSRGB = alpenglow.RenderLinearSRGBToSRGB;
          const RenderOklabToLinearSRGB = alpenglow.RenderOklabToLinearSRGB;
          const RenderLinearSRGBToOklab = alpenglow.RenderLinearSRGBToOklab;
          const RenderLinearDisplayP3ToLinearSRGB = alpenglow.RenderLinearDisplayP3ToLinearSRGB;
          const RenderLinearSRGBToLinearDisplayP3 = alpenglow.RenderLinearSRGBToLinearDisplayP3;
          const RenderBlendCompose = alpenglow.RenderBlendCompose;
          const RenderStack = alpenglow.RenderStack;
          const RenderPlanar = alpenglow.RenderPlanar;
          const RenderDepthSort = alpenglow.RenderDepthSort;
          const RenderLight = alpenglow.RenderLight;
          const RenderNormalDebug = alpenglow.RenderNormalDebug;
          const RenderPhong = alpenglow.RenderPhong;
          const RenderFilter = alpenglow.RenderFilter;
          const RenderGradientStop = alpenglow.RenderGradientStop;
          const RenderImage = alpenglow.RenderImage;
          const RenderLinearBlend = alpenglow.RenderLinearBlend;
          const RenderLinearBlendAccuracy = alpenglow.RenderLinearBlendAccuracy;
          const RenderBarycentricBlend = alpenglow.RenderBarycentricBlend;
          const RenderBarycentricBlendAccuracy = alpenglow.RenderBarycentricBlendAccuracy;
          const RenderBarycentricPerspectiveBlend = alpenglow.RenderBarycentricPerspectiveBlend;
          const RenderBarycentricPerspectiveBlendAccuracy = alpenglow.RenderBarycentricPerspectiveBlendAccuracy;
          const RenderLinearGradient = alpenglow.RenderLinearGradient;
          const RenderLinearGradientAccuracy = alpenglow.RenderLinearGradientAccuracy;
          const RenderRadialBlend = alpenglow.RenderRadialBlend;
          const RenderRadialBlendAccuracy = alpenglow.RenderRadialBlendAccuracy;
          const RenderRadialGradient = alpenglow.RenderRadialGradient;
          const RenderRadialGradientAccuracy = alpenglow.RenderRadialGradientAccuracy;
          const RenderResampleType = alpenglow.RenderResampleType;

          ${codeMirror.getValue()}
          ${options.jsAfter}
        )();
        export default value;`;

        // Assumes it's in a function, differently from the sandbox
        const dataURI = `data:text/javascript;base64,${btoa( code )}`;

        const program = ( await import( dataURI ) ).default;

        let element;
        if ( options.showInstructions ) {
          const container = document.createElement( 'div' );
          element = container;

          const createPre = contents => {
            const pre = document.createElement( 'pre' );
            pre.style.textAlign = 'left';
            pre.style.marginTop = '10px';
            pre.style.fontSize = '10px';
            pre.style.lineHeight = '12px';
            pre.textContent = contents;
            return pre;
          };

          const createHeader = name => {
            const h6 = document.createElement( 'h6' );
            h6.style.textAlign = 'left';
            h6.textContent = name;
            return h6;
          };

          container.appendChild( createHeader( 'RenderProgram' ) );
          container.appendChild( createPre( program.toRecursiveString() ) );

          if ( !program.simplified().equals( program ) ) {
            container.appendChild( createHeader( 'RenderProgram Simplified' ) );
            container.appendChild( createPre( program.simplified().toRecursiveString() ) );
          }

          const instructions = [];
          program.writeInstructions( instructions );

          container.appendChild( createHeader( 'Instructions' ) );
          container.appendChild( createPre( instructions.map( instruction => instruction.toString() ).join( '\n' ) ) );

          const encoder = new phet.alpenglow.ByteEncoder();
          phet.alpenglow.RenderInstruction.instructionsToBinary( encoder, instructions );

          let debugLines = encoder.getDebug32String().trim().split( '\n' );

          // Strip off the header line
          const outputDebugLines = [ debugLines[ 0 ] ];
          debugLines = debugLines.slice( 1 );

          let instructionAddress = 0;
          let dwords = 0;
          for ( let i = 0; i < debugLines.length; i++ ) {
            while ( i === dwords && instructionAddress < instructions.length ) {
              const instruction = instructions[ instructionAddress++ ];
              outputDebugLines.push( instruction.toString() );
              dwords += instruction.getBinaryLength();
            }
            if ( i === debugLines.length - 1 ) {
              outputDebugLines.push( 'RenderInstructionExit()' );
            }
            outputDebugLines.push( debugLines[ i ] );
          }

          container.appendChild( createHeader( 'Binary Instructions' ) );
          container.appendChild( createPre( outputDebugLines.join( '\n' ) ) );
        }
        else {
          element = window.getRasterizedElement( program, width, height, options );
        }

        // Clear content
        while ( displayContainerElement.firstChild ) {
          displayContainerElement.removeChild( displayContainerElement.lastChild );
        }
        displayContainerElement.appendChild( element );
        displayContainerElement.style.opacity = '100%';
      }
      catch( e ) {
        console.error( e );
        displayContainerElement.style.backgroundColor = 'rgba(255,0,0,0.2)';
        errorsContainerElement.style.display = 'block';
        errorsContainerElement.innerHTML = `<pre>${e}</pre>`;
        displayContainerElement.style.opacity = '50%';
      }
    };

    codeMirror.on( 'change', editor => run && run() );

    run();
  };

  setTimeout( () => {
    const addDiagram = ( id, callback ) => {
      const container = document.getElementById( id );
      if ( container ) {
        const diagram = callback();
        container.appendChild( diagram );
      }
    };
    window.addDiagram = addDiagram;
    window.pendingDiagrams.forEach( diagram => setTimeout( () => addDiagram( diagram.id, diagram.callback ), 0 ) );
  }, 0 );

  window.createSceneryDiagram = ( scene, width, height ) => {
    const div = document.createElement( 'div' );
    div.style.margin = '0 auto';
    const display = new Display( scene, {
      width: width,
      height: height,
      accessibility: true,
      container: div,
      allowCSSHacks: false
    } );
    display.updateDisplay();
    return div;
  };

</script>

<!-- Our code, in either the concatenated 'with comments' version or the minified version -->
<!--<script src="../../phet-lib/dist/phet-lib.debug.js"></script>-->
<!--<script src="../../phet-lib/dist/phet-lib.min.js"></script>-->

<div class="row-fluid">
  <div class="span2"></div>
  <div class="span8">
    <div class="page-header" style="text-align: center;">
      <h1>Alpenglow Plan &amp; Documentation</h1>
    </div>
  </div>
  <div class="span2"></div>
</div>

<div class="row-fluid">
  <div class="span2 hidden-phone">
    <ul class="nav nav-list">
      <li><a href="#overview">Overview</a></li>
      <li>
        <a href="#concepts">Concepts</a>
        <ul class="nav nav-list">
          <li><a href="#polygonalFaces">Polygonal Faces</a></li>
          <li><a href="#clipping">Clipping</a></li>
          <li><a href="#booleanOperations">Boolean Operations</a></li>
          <li>
            <a href="#antialiasing">Anti-Aliasing</a>
            <ul class="nav nav-list">
              <li><a href="#antialiasing-integrals">Integrals</a></li>
              <li><a href="#antialiasing-filters">Filters</a></li>
              <li><a href="#antialiasing-examples">Examples</a></li>
            </ul>
          </li>
          <li>
            <a href="#color-and-blending">Color &amp; Blending</a>
          </li>
          <li>
            <a href="#renderProgram">RenderProgram</a>
            <ul class="nav nav-list">
              <li><a href="#RenderColor">RenderColor</a></li>
              <li><a href="#RenderPathBoolean">RenderPathBoolean</a></li>
              <li><a href="#RenderStack">RenderStack</a></li>
              <li><a href="#RenderLinearBlend">RenderLinearBlend</a></li>
              <li><a href="#RenderLinearGradient">RenderLinearGradient</a></li>
              <li><a href="#RenderRadialBlend">RenderRadialBlend</a></li>
              <li><a href="#RenderRadialGradient">RenderRadialGradient</a></li>
              <li><a href="#RenderBlendCompose">RenderBlendCompose</a></li>
              <li><a href="#renderProgram-simplification">Simplification</a></li>
              <li><a href="#renderProgram-execution">Execution</a></li>
            </ul>
          </li>
          <li>
            <a href="#WGSL">WGSL</a>
            <ul class="nav nav-list">
              <li><a href="#WGSL-snippets">Snippets</a></li>
              <li><a href="#WGSL-preprocessing">Preprocessing</a></li>
              <li><a href="#WGSL-minification">Minification</a></li>
              <li><a href="#WGSL-mangling">Mangling</a></li>
              <li><a href="#WGSL-algorithms">Algorithms</a></li>
              <li><a href="#WGSL-reduce">Reduce</a></li>
              <li><a href="#WGSL-scan">Scan</a></li>
              <li><a href="#WGSL-radixSort">Radix Sort</a></li>
              <li><a href="#WGSL-mergeSort">Merge Sort</a></li>
              <li><a href="#WGSL-memory">Memory</a></li>
              <li><a href="#WGSL-rationals">Rationals</a></li>
              <li><a href="#WGSL-profiling">Profiling</a></li>
            </ul>
          </li>
          <li><a href="#asyncSimulation">Async Simulation</a></li>
          <li><a href="#depthSort">Depth Sort</a></li>
          <li><a href="#vectorCanvas">Vector Canvas</a></li>
        </ul>
      </li>
      <li>
        <a href="#stages">Stages</a>
        <ul class="nav nav-list">
          <li><a href="#stage-transforms">Transforms</a></li>
          <li><a href="#stage-subdivision">Subdivision</a></li>
          <li><a href="#stage-bounds">Bounds</a></li>
          <li><a href="#stage-tiling">Tiling</a></li>
          <li><a href="#stage-integerTransform">Integer Transform</a></li>
          <li><a href="#stage-hilbertSort">Hilbert Sort</a></li>
          <li><a href="#stage-intersection">Intersection</a></li>
          <li><a href="#stage-split">Split</a></li>
          <li><a href="#stage-edgeSort">Edge Sort</a></li>
          <li><a href="#stage-filterConnect">Filter &amp; Connect</a></li>
          <li><a href="#stage-boundaryTrace">Boundary Trace</a></li>
          <li><a href="#stage-faceHoles">Face Holes</a></li>
          <li><a href="#stage-windingMaps">Winding Maps</a></li>
          <li><a href="#stage-renderProgramSimplification">RenderProgram Simplification</a></li>
          <li><a href="#stage-renderableFaceCreation">RenderableFace Creation</a></li>
          <li><a href="#stage-splitPrograms">Split Programs</a></li>
          <li><a href="#stage-rasterize">Rasterize</a></li>
        </ul>
      </li>
    </ul>
  </div>
  <div class="span8">
    <h2 id="overview">Overview</h2>

    <p>
      Alpenglow is an experimental rasterizer. It is meant to take in a scene description and efficiently output the
      corresponding image.
    </p>

    <p>
      <strong>
        Please contact the author (Jonathan Olson, jonathan.olson@colorado.edu) for any questions or comments, no matter how small!
      </strong>
    </p>

    <p class="TODO">
      Get this built and running on GitHub pages
    </p>

    <p class="TODO">
      Add TODO levels here, so we can flag critical/important ones. Also, make them searchable?
    </p>

    <p class="TODO">
      Get the demos from demos.html moved into here, so we can ditch the old code.
    </p>

    <p class="TODO">
      Add "loading" indicators for the diagrams, so we don't trigger reflows.
    </p>

    <p class="TODO">
      Get font changes done with Scenery vello branch, so we can include code improvements and get RenderFromNode working
      better. Also allows showing Vello stuff in demos (will need to see if we can port over the multi branch work).
      Merge multi-work. Remove auto-feature-detect for now, so it doesn't ping shaders on main?
    </p>

    <p class="TODO">
      Improve styling, see <a href="https://getbootstrap.com/2.3.2/scaffolding.html">Old Bootstrap docs</a>.
    </p>

    <h3>Technology: Primarily WebGPU</h3>

    <p>
      The goal is to primarily use WebGPU for rendering, but to also support WebGL 2 as much as possible, with software
      fallback (and for testing/development). In addition to a normal software route, there is a async/await
      parallelized form that can execute with the same execution model that WebGPU would use (with workgroups, storage
      buffers, etc.), that is used for validation, testing, and debugging.
    </p>

    <p class="TODO">
      Consider WebWorkers, and whether we can use them efficiently for any of the initial steps (instead of putting
      all the work on the GPU).
    </p>

    <h3>Methods: Solve the Occlusion Problem First</h3>

    <p>
      The goal is to solve the problem quickly and with high quality by using polygonal boolean-operation
      approaches where we can get a list of polygonal faces where each input path is either fully contained or fully
      excluded in each face. We can then use high-performance approaches to rasterize each face independently, then
      accumulate while avoiding multisampling and conflation artifacts. Often these faces will be of constant color,
      which can very efficiently be displayed (we skip the per-pixel blending with the completely-occluded background
      contents).
    </p>

    <div class="row-fluid">
      <div class="span4 example">
        <div id="conflation-canvas"></div>
        Conflation artifacts (Canvas)
      </div>
      <div class="span4 example">
        <div id="conflation-svg"></div>
        Conflation artifacts (SVG)
      </div>
      <div class="span4 example">
        <div id="conflation-default"></div>
        No artifacts (Alpenglow CPU)
      </div>
    </div>

    <script type="module">
      import { Color, Node, Path, Rectangle } from '../../chipper/dist/js/scenery/js/imports.js';
      import { RenderColor, RenderStack, RenderPathBoolean, RenderPath, RenderFromNode, RenderColorSpace } from '../../chipper/dist/js/alpenglow/js/imports.js';
      import { Shape } from '../../chipper/dist/js/kite/js/imports.js';
      import Vector2 from '../../chipper/dist/js/dot/js/Vector2.js';
      import dot from '../../chipper/dist/js/dot/js/dot.js';
      const v2 = dot.v2;
      const v4 = dot.v4;

      const getConflation = ( type, pointCount ) => {
        const width = 128;
        const height = 128;

        const center = v2( width / 2 + 0.15992094, height / 2 + 0.426296 );
        const radius = width * 0.45;

        const polygons = [];
        const colors = [];
        for ( let i = 0; i < pointCount; i++ ) {
          const polygon = [];
          const angle0 = i * 2 * Math.PI / pointCount;
          const angle1 = ( i + 1 ) * 2 * Math.PI / pointCount;

          const chroma = Vector2.createPolar( 0.1, angle0 );
          colors.push( RenderColor.gamutMapSRGB( RenderColor.convert( v4( 0.5, chroma.x, chroma.y, 1 ), RenderColorSpace.oklab, RenderColorSpace.sRGB ) ) );

          const p0 = v2( center.x + radius * Math.cos( angle0 ), center.y + radius * Math.sin( angle0 ) );
          const p1 = v2( center.x + radius * Math.cos( angle1 ), center.y + radius * Math.sin( angle1 ) );

          polygon.push( center );
          polygon.push( p0 );
          polygon.push( p1 );
          polygons.push( polygon );
        }

        if ( type === 'svg' || type === 'canvas' || type === 'vello' ) {
          return window.getSceneryElement(
            new Node( {
              children: [
                new Rectangle( 0, 64, 128, 64, { fill: 'black' } ),
                ...polygons.map( ( poly, i ) => {
                  return new Path( Shape.polygon( poly ), { fill: new Color( colors[ i ].x * 255, colors[ i ].y * 255, colors[ i ].z * 255, 1 ) } );
                } )
              ]
            } ),
            width, height, 'white', type
          );
        }
        else if ( type === 'default' ) {
          const program = new RenderStack(
            [
              new RenderPathBoolean(
                new RenderPath( 'nonzero', [ [
                  v2( 0, 64 ),
                  v2( 128, 64 ),
                  v2( 128, 128 ),
                  v2( 0, 128 )
                ] ] ),
                RenderFromNode.colorFrom( 'black' ),
                RenderFromNode.colorFrom( 'white' )
              ),
              ...polygons.map( ( polygon, i ) => new RenderPathBoolean(
                new RenderPath( 'nonzero', [ polygon ] ),
                new RenderColor( colors[ i ] ),
                RenderColor.TRANSPARENT
              ) )
            ]
          );

          return window.getRasterizedElement( program, width, height );
        }
        else {
          throw new Error( 'unknown type' );
        }
      };

      window.addDiagram( 'conflation-canvas', () => getConflation( 'canvas', 100 ) );
      window.addDiagram( 'conflation-svg', () => getConflation( 'svg', 100 ) );
      window.addDiagram( 'conflation-default', () => getConflation( 'default', 100 ) );
    </script>

    <p>
      Also see <a href="https://w3.impa.br/~diego/projects/GanEtAl14/sample.html?contour">more conflation examples</a>.
    </p>

    <h2 id="concepts">Concepts</h2>

    <h3 id="polygonalFaces">Polygonal Faces</h3>

    <p>
      Polygonal faces are used pervasively throughout Alpenglow. In general, our data structures are designed to support
      <a href="https://en.wikipedia.org/wiki/Polygon_with_holes">polygons with holes</a>, and more generally, the
      primitive is a "list of polygons". An example is the following diagram, which can be stored in different ways:
    </p>

    <div class="example">
      <div id="polygonal-face-example"></div>
    </div>

    <p>
      All of the storage representations below conform to the <code>ClippableFace</code> interface in the software
      implementation.
    </p>

    <h4>Polygonal Form</h4>

    <p>
      It can be represented in the polygonal form as three (directed) lists of vertices (with a <a href="https://en.wikipedia.org/wiki/Nonzero-rule">nonzero winding rule</a>):
    </p>

    <p>
      (0,&nbsp;0),
      (10,&nbsp;0),
      (10,&nbsp;2),
      (2,&nbsp;10),
      (0,&nbsp;10)
      <br>
      (2,&nbsp;2),
      (2,&nbsp;7),
      (7,&nbsp;2)
      <br>
      (9,&nbsp;9),
      (6,&nbsp;9),
      (9,&nbsp;6)
    </p>

    <p>
      where there is a line (edge) between each consecutive pair of vertices, and the last vertex is connected to the
      first vertex. This is compact, however the order is critical. This can cause certain operations (e.g. circular
      clipping, some tracing) to be slower than other methods. This is handled by <code>PolygonalFace</code> in the
      software implementation.
    </p>

    <h4>Edge Form</h4>

    <p>
      For much of Alpenglow's needs, things work better if we consider the list of edges itself (with start/end vertices):
    </p>

    <p>
      (0,&nbsp;0)&nbsp;=>&nbsp;(10,&nbsp;0),
      (10,&nbsp;0)&nbsp;=>&nbsp;(10,&nbsp;2),
      (10,&nbsp;2)&nbsp;=>&nbsp;(2,&nbsp;10),
      (2,&nbsp;10)&nbsp;=>&nbsp;(0,&nbsp;10),
      (0,&nbsp;10)&nbsp;=>&nbsp;(0,&nbsp;0)

      (2,&nbsp;2)&nbsp;=>&nbsp;(2,&nbsp;7),
      (2,&nbsp;7)&nbsp;=>&nbsp;(7,&nbsp;2),
      (7,&nbsp;2)&nbsp;=>&nbsp;(2,&nbsp;2)

      (9,&nbsp;9)&nbsp;=>&nbsp;(6,&nbsp;9),
      (6,&nbsp;9)&nbsp;=>&nbsp;(9,&nbsp;6),
      (9,&nbsp;6)&nbsp;=>&nbsp;(9,&nbsp;9)
    </p>

    <p>
      Now, for most critical operations, order doesn't matter, and each edge can be considered in isolation.
      We won't need to sort things during/after operations, but also certain operations might need to generate more
      edges that get canceled out (whereas with polygonal data, we could detect it and simplify in higher-performance
      ways). This form is handled by <code>EdgedFace</code> in the software implementation.
    </p>

    <h4>Degenerate Edges</h4>

    <p>
      Additionally, we can actually construct this with an equivalent single (degenerate) polygon. Since we only care
      about the filled area, it turns out that edges that "reverse" over each other won't contribute to the filled area,
      so we can double-back. Thus the following diagram:
    </p>

    <div class="example">
      <div id="polygonal-face-canceling"></div>
    </div>

    <p>
      can be constructed with an equivalent area with the following polygon:
    </p>

    <p>
      (0,&nbsp;0),
      (10,&nbsp;0),
      (10,&nbsp;2),
      (7,&nbsp;2),
      (2,&nbsp;2),
      (2,&nbsp;7),
      (6,&nbsp;9),
      (9,&nbsp;6),
      (9,&nbsp;9),
      (6,&nbsp;9),
      (2,&nbsp;7),
      (7,&nbsp;2),
      (10,&nbsp;2),
      (2,&nbsp;10),
      (0,&nbsp;10)
    </p>

    <h4>Edge-Clipped Form</h4>

    <p>
      It turns out, for computational complexity of future clipping operations (see below), it is very helpful to NOT
      directly store the edges that go along the full edge of the clipping rectangle (e.g. the 0,0 to 10,10 region in
      the diagram). Instead, those edges will be counted. Due to the property above of degenerate edges, these counts
      can be added together to add the contribution of these "clipped" edges.
    </p>

    <p>
      The diagram below shows the edge orientations that get positive (+1) counts. Reversed edges will get negative (-1)
      counts:
    </p>

    <div class="example">
      <div id="polygonal-face-edge-clips"></div>
    </div>

    <p>
      Thus the edge-clipped version (for the 0,0 to 10,10 bounds) will have the following edges and counts:
    </p>

    <div class="example">
      <div id="polygonal-face-edge-clipped"></div>
    </div>

    <p>
      (10,&nbsp;0)&nbsp;=>&nbsp;(10,&nbsp;2),
      (10,&nbsp;2)&nbsp;=>&nbsp;(2,&nbsp;10),
      (2,&nbsp;10)&nbsp;=>&nbsp;(0,&nbsp;10),

      (2,&nbsp;2)&nbsp;=>&nbsp;(2,&nbsp;7),
      (2,&nbsp;7)&nbsp;=>&nbsp;(7,&nbsp;2),
      (7,&nbsp;2)&nbsp;=>&nbsp;(2,&nbsp;2)

      (9,&nbsp;9)&nbsp;=>&nbsp;(6,&nbsp;9),
      (6,&nbsp;9)&nbsp;=>&nbsp;(9,&nbsp;6),
      (9,&nbsp;6)&nbsp;=>&nbsp;(9,&nbsp;9)
    </p>

    <p>
      This is handled by the <code>EdgedClippedFace</code> in the software implementation.
    </p>

    <p class="TODO">
      Create "Bounds Pyramid" immutable data structure. It's a binary tree, leaves are edges. Each level stores the
      bounding box. PIP-tests are VERY accelerated on this. Clipping also potentially will be (if a node is fully within
      one side of a binary clip, we can just INCLUDE that node). Thus we'll have a linked list way of describing how
      the nodes connect (so we can reuse parts of the source within the result). At a certain point, this will be less
      beneficial, but high-up it might be very helpful? Test PIP and clipping with this. (each section has bounds and
      children). Linked list so we can store "sequences" immutably, that don't get changed.
    </p>

    <p class="TODO">
      Grid clips with bounds-pyramids could be even more efficient on the CPU. Does it really help with the GPU at all?
      When clipped, recompute bounds (will be tighter)? Or at a certain point, do we stop recomputing bounds?
    </p>

    <script type="module">
      import ArrowNode from '../../chipper/dist/js/scenery-phet/js/ArrowNode.js';

      const outputSize = 256;
      const size = 10;
      const padding = 40;

      const matrix = phet.dot.Matrix3.translation( padding, padding ).timesMatrix( phet.dot.Matrix3.scaling( ( outputSize - 2 * padding ) / size ) );
      const bounds = new phet.dot.Bounds2( 0, 0, 10, 10 );

      const dottedRect = phet.scenery.Rectangle.bounds( bounds.transformed( matrix ), {
        stroke: 'black',
        lineWidth: 0.5,
        lineDash: [ 2, 2 ]
      } );

      const v2 = phet.dot.v2;
      const polygons = [
        [
          v2( 0, 0 ),
          v2( 10, 0 ),
          v2( 10, 2 ),
          v2( 2, 10 ),
          v2( 0, 10 )
        ],
        [
          v2( 2, 2 ),
          v2( 2, 7 ),
          v2( 7, 2 )
        ],
        [
          v2( 9, 9 ),
          v2( 6, 9 ),
          v2( 9, 6 )
        ]
      ];

      const shape = phet.alpenglow.LinearEdge.polygonsToShape( polygons ).transformed( matrix );
      const edges = phet.alpenglow.LinearEdge.fromPolygons( polygons );

      const filledPath = new phet.scenery.Path( shape, {
        fill: 'rgba(255,0,0,0.7)'
      } );

      const arrowOptions = {
        headHeight: 6,
        headWidth: 4,
        tailWidth: 0.2
      };

      const arrowsNode = new phet.scenery.Node( {
        children: edges.map( edge => {
          const start = matrix.timesVector2( edge.startPoint );
          const end = matrix.timesVector2( edge.endPoint );
          return new ArrowNode( start.x, start.y, end.x, end.y, arrowOptions );
        } )
      } );

      const edgeClippedArrowsNode = new phet.scenery.Node( {
        children: edges.map( edge => {
          if ( ( edge.startPoint.x === 0 && edge.startPoint.y === 0 ) || ( edge.endPoint.x === 0 && edge.endPoint.y === 0 ) ) {
            return null;
          }
          const start = matrix.timesVector2( edge.startPoint );
          const end = matrix.timesVector2( edge.endPoint );
          return new ArrowNode( start.x, start.y, end.x, end.y, arrowOptions );
        } ).filter( _.identity )
      } );

      const toArray = v => [ v.x, v.y ];
      const extraArrowsNode = new phet.scenery.Node( {
        children: [
          new ArrowNode(
            ...toArray( matrix.timesVector2( v2( 10, 1.93 ) ) ),
            ...toArray( matrix.timesVector2( v2( 7, 1.93 ) ) ),
            arrowOptions
          ),
          new ArrowNode(
            ...toArray( matrix.timesVector2( v2( 7, 2.07 ) ) ),
            ...toArray( matrix.timesVector2( v2( 10, 2.07 ) ) ),
            arrowOptions
          ),
          new ArrowNode(
            ...toArray( matrix.timesVector2( v2( 2, 7.08 ) ) ),
            ...toArray( matrix.timesVector2( v2( 6, 9.08 ) ) ),
            arrowOptions
          ),
          new ArrowNode(
            ...toArray( matrix.timesVector2( v2( 6, 8.92 ) ) ),
            ...toArray( matrix.timesVector2( v2( 2, 6.92 ) ) ),
            arrowOptions
          )
        ]
      } );

      const edgeClipArrowsNode = new phet.scenery.Node( {
        children: [
          new ArrowNode(
            ...toArray( matrix.timesVector2( v2( 0, 0 ) ) ),
            ...toArray( matrix.timesVector2( v2( 0, 10 ) ) ),
            phet.phetCore.merge( { fill: 'red', stroke: 'red' }, arrowOptions )
          ),
          new ArrowNode(
            ...toArray( matrix.timesVector2( v2( 0, 0 ) ) ),
            ...toArray( matrix.timesVector2( v2( 10, 0 ) ) ),
            phet.phetCore.merge( { fill: 'red', stroke: 'red' }, arrowOptions )
          ),
          new ArrowNode(
            ...toArray( matrix.timesVector2( v2( 10, 0 ) ) ),
            ...toArray( matrix.timesVector2( v2( 10, 10 ) ) ),
            phet.phetCore.merge( { fill: 'red', stroke: 'red' }, arrowOptions )
          ),
          new ArrowNode(
            ...toArray( matrix.timesVector2( v2( 0, 10 ) ) ),
            ...toArray( matrix.timesVector2( v2( 10, 10 ) ) ),
            phet.phetCore.merge( { fill: 'red', stroke: 'red' }, arrowOptions )
          )
        ]
      } );

      const edgeClipArrowLabelsNode = new phet.scenery.Node( {
        children: [
          new phet.scenery.Text( 'minY', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 5, -0.1 ) ) } ),
          new phet.scenery.Text( 'maxY', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 5, 10.1 ) ) } ),
          new phet.scenery.Text( 'minX', { font: window.diagramFont, rightCenter: matrix.timesVector2( v2( -0.1, 5 ) ) } ),
          new phet.scenery.Text( 'maxX', { font: window.diagramFont, leftCenter: matrix.timesVector2( v2( 10.1, 5 ) ) } )
        ]
      } );

      const edgeClippedArrowLabelsNode = new phet.scenery.Node( {
        children: [
          new phet.scenery.Text( '+1', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 5, -0.1 ) ) } ),
          new phet.scenery.Text( '0', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 5, 10.1 ) ) } ),
          new phet.scenery.Text( '-1', { font: window.diagramFont, rightCenter: matrix.timesVector2( v2( -0.1, 5 ) ) } ),
          new phet.scenery.Text( '0', { font: window.diagramFont, leftCenter: matrix.timesVector2( v2( 10.1, 5 ) ) } )
        ]
      } );

      const coordinateLabelsNode = new phet.scenery.Node( {
        children: [
          new phet.scenery.Text( '(0,0)', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 0, -0.1 ) ) } ),
          new phet.scenery.Text( '(0,10)', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 0, 10.1 ) ) } ),
          new phet.scenery.Text( '(10,0)', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 10, -0.1 ) ) } ),
          new phet.scenery.Text( '(9,9)', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 9, 9.1 ) ) } ),
          new phet.scenery.Text( '(6,9)', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 6, 9.1 ) ) } ),
          new phet.scenery.Text( '(9,6)', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 9, 5.9 ) ) } ),
          new phet.scenery.Text( '(2,10)', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 2, 10.1 ) ) } ),
          new phet.scenery.Text( '(10,2)', { font: window.diagramFont, leftCenter: matrix.timesVector2( v2( 10.1, 2 ) ) } ),
          new phet.scenery.Text( '(2,2)', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 2, 1.9 ) ) } ),
          new phet.scenery.Text( '(7,2)', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 7, 1.9 ) ) } ),
          new phet.scenery.Text( '(2,7)', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 2, 7.1 ) ) } )
        ]
      } );

      const cornerCoordinateLabelsNode = new phet.scenery.Node( {
        children: [
          new phet.scenery.Text( '(0,0)', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 0, -0.1 ) ) } ),
          new phet.scenery.Text( '(0,10)', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 0, 10.1 ) ) } ),
          new phet.scenery.Text( '(10,0)', { font: window.diagramFont, centerBottom: matrix.timesVector2( v2( 10, -0.1 ) ) } ),
          new phet.scenery.Text( '(10,10)', { font: window.diagramFont, centerTop: matrix.timesVector2( v2( 10, 10.1 ) ) } )
        ]
      } );

      // TODO: factor some of this code out...
      window.addDiagram( 'polygonal-face-example', () => window.createSceneryDiagram(
        new phet.scenery.Node( {
          children: [
            dottedRect,
            filledPath,
            arrowsNode,
            coordinateLabelsNode
          ]
        } ),
        outputSize, outputSize
      ) );

      window.addDiagram( 'polygonal-face-canceling', () => window.createSceneryDiagram(
        new phet.scenery.Node( {
          children: [
            dottedRect,
            filledPath,
            arrowsNode,
            extraArrowsNode
          ]
        } ),
        outputSize, outputSize
      ) );

      window.addDiagram( 'polygonal-face-edge-clips', () => window.createSceneryDiagram(
        new phet.scenery.Node( {
          children: [
            dottedRect,
            edgeClipArrowsNode,
            cornerCoordinateLabelsNode,
            edgeClipArrowLabelsNode
          ]
        } ),
        outputSize, outputSize
      ) );

      window.addDiagram( 'polygonal-face-edge-clipped', () => window.createSceneryDiagram(
        new phet.scenery.Node( {
          children: [
            dottedRect,
            filledPath,
            edgeClippedArrowsNode,
            coordinateLabelsNode,
            edgeClippedArrowLabelsNode
          ]
        } ),
        outputSize, outputSize
      ) );
    </script>

    <h3 id="clipping">Clipping</h3>

    <h4>Line Clipping</h4>

    The first primitive we'll need is the ability to find the part of a line segment that is within an axis-aligned
    bounding rectangle (referred to as bounds). Alpenglow primarily uses <a href="https://aircconline.com/ijcga/V9N3/9319ijcga01.pdf">Another Simple but Faster Method for 2D Line Clipping</a> by
    Matthes and Drakopoulos (2019).

    <div class="example">
      <div id="clipping-line-example"></div>
    </div>

    <script type="module">
      const outputSize = 256;
      const size = 10;
      const padding = 70;

      const matrix = phet.dot.Matrix3.translation( padding, padding ).timesMatrix( phet.dot.Matrix3.scaling( ( outputSize - 2 * padding ) / size ) );
      const bounds = new phet.dot.Bounds2( 0, 0, 10, 10 );

      const clipRect = phet.scenery.Rectangle.bounds( bounds.transformed( matrix ), {
        stroke: 'black',
        fill: 'white'
      } );

      const exteriorShape = new phet.kite.Shape();
      const interiorShape = new phet.kite.Shape();

      const v2 = phet.dot.v2;
      const LinearEdge = phet.alpenglow.LinearEdge;
      const edges = [
        new LinearEdge( v2( -2, 7 ), v2( 7, -2 ) ),
        new LinearEdge( v2( 3, 4 ), v2( 9, 6 ) ),
        new LinearEdge( v2( 5, -5 ), v2( 15, 4 ) ),
        new LinearEdge( v2( 4, 7 ), v2( 9, 12 ) ),
        new LinearEdge( v2( 2, 10 ), v2( 1, 13 ) ),
        new LinearEdge( v2( 0, 9 ), v2( 2, 9 ) )
      ];

      for ( let i = 0; i < edges.length; i++ ) {
        const start = edges[ i ].startPoint.copy();
        const end = edges[ i ].endPoint.copy();

        const fullStart = start.copy();
        const fullEnd = end.copy();

        const clipped = phet.alpenglow.LineClipping.matthesDrakopoulosClip( start, end, 0, 0, 10, 10 );

        if ( clipped ) {
          if ( !start.equals( fullStart ) ) {
            exteriorShape.moveToPoint( matrix.timesVector2( fullStart ) );
            exteriorShape.lineToPoint( matrix.timesVector2( start ) );
          }

          if ( !start.equals( end ) ) {
            interiorShape.moveToPoint( matrix.timesVector2( start ) );
            interiorShape.lineToPoint( matrix.timesVector2( end ) );
          }

          if ( !end.equals( fullEnd ) ) {
            exteriorShape.moveToPoint( matrix.timesVector2( end ) );
            exteriorShape.lineToPoint( matrix.timesVector2( fullEnd ) );
          }
        }
        else {
          exteriorShape.moveToPoint( matrix.timesVector2( fullStart ) );
          exteriorShape.lineToPoint( matrix.timesVector2( fullEnd ) );
        }
      }

      const exteriorNode = new phet.scenery.Path( exteriorShape, {
        stroke: 'black',
        opacity: 0.2
      } );
      const interiorNode = new phet.scenery.Path( interiorShape, {
        stroke: 'red'
      } );

      window.addDiagram( 'clipping-line-example', () => window.createSceneryDiagram(
        new phet.scenery.Node( {
          children: [
            clipRect,
            exteriorNode,
            interiorNode
          ]
        } ),
        outputSize, outputSize
      ) );
    </script>

    <p class="TODO">Documentation</p>

    <p class="TODO">Edge-Clipped note about preservation of counts</p>

    <p class="TODO">Circular clipping and other types. Write up dual concept of clipping.</p>

    <p class="TODO">
      Read Skala summary of clipping, see if I'm missing something. Also
      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9605407/">this looks valuable as an intro for others.</a>
    </p>

    <p class="TODO">
      Stripe clipping gets messed up with fake edges. Vaguely? Investigate.
    </p>

    <h3 id="booleanOperations">Boolean Operations</h3>

    <p class="TODO">
      Describe the general overview of our polygonal overlay computations.
    </p>

    <p class="TODO">
      Check "standalone" performance against other robust implementations?
    </p>

    <p class="TODO">
      Review <a href="https://www.mdpi.com/2073-8994/10/10/477">paper</a>
    </p>

    <div class="example">
      <div id="boolean-operations-example"></div>
      Example boolean operation, intersection shown in blue, differences shown in red and green.
    </div>

    <script type="module">
      import { Node, Path } from '../../chipper/dist/js/scenery/js/imports.js';
      import { LinearEdge, RenderPath, PolygonalBoolean } from '../../chipper/dist/js/alpenglow/js/imports.js';
      const scene = new Node();

      const shapeAData = 'M 35.20000000000000284217 -15.15000000000000035527 L 35.20000000000000284217 -7.20000000000000017764 Q 35.20000000000000284217 -4.22500000000000053291 33.08749999999999857891 -2.11250000000000026645 Q 30.97500000000000142109 0.00000000000000000000 28.00000000000000000000 0.00000000000000000000 L 7.20000000000000017764 0.00000000000000000000 Q 4.22500000000000053291 0.00000000000000000000 2.11250000000000026645 -2.11250000000000026645 Q 0.00000000000000000000 -4.22500000000000053291 0.00000000000000000000 -7.20000000000000017764 L 0.00000000000000000000 -28.00000000000000000000 Q 0.00000000000000000000 -30.97500000000000142109 2.11250000000000026645 -33.08749999999999857891 Q 4.22500000000000053291 -35.20000000000000284217 7.20000000000000017764 -35.20000000000000284217 L 28.00000000000000000000 -35.20000000000000284217 Q 29.57500000000000284217 -35.20000000000000284217 30.92500000000000071054 -34.57500000000000284217 Q 31.30000000000000071054 -34.39999999999999857891 31.37500000000000000000 -34.00000000000000000000 Q 31.45000000000000284217 -33.57500000000000284217 31.15000000000000213163 -33.27499999999999857891 L 29.92500000000000071054 -32.05000000000000426326 Q 29.67500000000000071054 -31.80000000000000071054 29.35000000000000142109 -31.80000000000000071054 Q 29.27500000000000213163 -31.80000000000000071054 29.12500000000000000000 -31.85000000000000142109 Q 28.55000000000000071054 -32.00000000000000000000 28.00000000000000000000 -32.00000000000000000000 L 7.20000000000000017764 -32.00000000000000000000 Q 5.55000000000000071054 -32.00000000000000000000 4.37500000000000000000 -30.82500000000000284217 Q 3.20000000000000017764 -29.65000000000000213163 3.20000000000000017764 -28.00000000000000000000 L 3.20000000000000017764 -7.20000000000000017764 Q 3.20000000000000017764 -5.55000000000000071054 4.37500000000000000000 -4.37500000000000000000 Q 5.55000000000000071054 -3.20000000000000017764 7.20000000000000017764 -3.20000000000000017764 L 28.00000000000000000000 -3.20000000000000017764 Q 29.65000000000000213163 -3.20000000000000017764 30.82500000000000284217 -4.37500000000000000000 Q 32.00000000000000000000 -5.55000000000000071054 32.00000000000000000000 -7.20000000000000017764 L 32.00000000000000000000 -13.55000000000000071054 Q 32.00000000000000000000 -13.87500000000000000000 32.22500000000000142109 -14.10000000000000142109 L 33.82500000000000284217 -15.70000000000000106581 Q 34.07500000000000284217 -15.95000000000000106581 34.39999999999999857891 -15.95000000000000106581 Q 34.55000000000000426326 -15.95000000000000106581 34.70000000000000284217 -15.87500000000000000000 Q 35.20000000000000284217 -15.67500000000000071054 35.20000000000000284217 -15.15000000000000035527 Z M 40.97500000000000142109 -27.37500000000000000000 L 20.62500000000000000000 -7.02500000000000035527 Q 20.02500000000000213163 -6.42500000000000071054 19.20000000000000284217 -6.42500000000000071054 Q 18.37500000000000000000 -6.42500000000000071054 17.77500000000000213163 -7.02500000000000035527 L 7.02500000000000035527 -17.77500000000000213163 Q 6.42500000000000071054 -18.37500000000000000000 6.42500000000000071054 -19.20000000000000284217 Q 6.42500000000000071054 -20.02500000000000213163 7.02500000000000035527 -20.62500000000000000000 L 9.77500000000000035527 -23.37500000000000000000 Q 10.37500000000000000000 -23.97500000000000142109 11.20000000000000106581 -23.97500000000000142109 Q 12.02500000000000035527 -23.97500000000000142109 12.62500000000000000000 -23.37500000000000000000 L 19.20000000000000284217 -16.80000000000000071054 L 35.37500000000000000000 -32.97500000000000142109 Q 35.97500000000000142109 -33.57500000000000284217 36.80000000000000426326 -33.57500000000000284217 Q 37.62500000000000000000 -33.57500000000000284217 38.22500000000000142109 -32.97500000000000142109 L 40.97500000000000142109 -30.22500000000000142109 Q 41.57500000000000284217 -29.62500000000000000000 41.57500000000000284217 -28.80000000000000071054 Q 41.57500000000000284217 -27.97500000000000142109 40.97500000000000142109 -27.37500000000000000000 Z';
      const shapeBData = 'M 320.00000000000000000000 400.00000000000000000000 C 244.15000000000000568434 400.00000000000000000000 182.75000000000000000000 341.29000000000002046363 177.09999999999999431566 266.88999999999998635758 L 72.20000000000000284217 185.81999999999999317879 C 58.41000000000000369482 203.12000000000000454747 45.71999999999999886313 221.40999999999999658939 35.48000000000000397904 241.40999999999999658939 A 32.35000000000000142109 32.35000000000000142109 0 0 0 35.48000000000000397904 270.60000000000002273737 C 89.70999999999999374722 376.41000000000002501110 197.06999999999999317879 448.00000000000000000000 320.00000000000000000000 448.00000000000000000000 C 346.91000000000002501110 448.00000000000000000000 372.87000000000000454747 444.00000000000000000000 397.88999999999998635758 437.54000000000002046363 L 346.00000000000000000000 397.38999999999998635758 A 144.12999999999999545253 144.12999999999999545253 0 0 1 319.99999999999994315658 400.00000000000000000000 Z M 633.81999999999993633537 458.10000000000002273737 L 523.26999999999998181011 372.66000000000002501110 A 331.25000000000000000000 331.25000000000000000000 0 0 0 604.51999999999998181011 270.59000000000003183231 A 32.35000000000000142109 32.35000000000000142109 0 0 0 604.51999999999998181011 241.40000000000003410605 C 550.28999999999996362021 135.59000000000000341061 442.93000000000000682121 64.00000000000000000000 320.00000000000000000000 64.00000000000000000000 A 308.14999999999997726263 308.14999999999997726263 0 0 0 172.68000000000000682121 101.69999999999987494448 L 45.46000000000000085265 3.37000000000000010658 A 16.00000000000000000000 16.00000000000000000000 0 0 0 23.00000000000000710543 6.17999999999999616307 L 3.37000000000000010658 31.44999999999999928946 A 16.00000000000000000000 16.00000000000000000000 0 0 0 6.18000000000001215028 53.89999999999999857891 L 594.53999999999996362021 508.62999999999999545253 A 16.00000000000000000000 16.00000000000000000000 0 0 0 617.00000000000000000000 505.81999999999999317879 L 636.63999999999998635758 480.55000000000001136868 A 16.00000000000000000000 16.00000000000000000000 0 0 0 633.81999999999993633537 458.10000000000007958079 Z M 450.09999999999990905053 316.10000000000002273737 L 410.79999999999989768185 285.72000000000002728484 A 94.75000000000000000000 94.75000000000000000000 0 0 0 416.00000000000000000000 256.00000000000005684342 A 94.76000000000000511591 94.76000000000000511591 0 0 0 294.68999999999982719601 163.79000000000007730705 A 47.64999999999999857891 47.64999999999999857891 0 0 1 304.00000000000000000000 192.00000000000000000000 A 46.64000000000000056843 46.64000000000000056843 0 0 1 302.46000000000003637979 201.99999999999988631316 L 228.84999999999996589395 145.11000000000001364242 A 142.31000000000000227374 142.31000000000000227374 0 0 1 319.99999999999994315658 112.00000000000000000000 A 143.91999999999998749445 143.91999999999998749445 0 0 1 464.00000000000000000000 256.00000000000005684342 C 464.00000000000000000000 277.62999999999999545253 458.70999999999997953637 297.79000000000002046363 450.10000000000002273737 316.11000000000001364242 L 450.09999999999990905053 316.10000000000002273737 Z';

      const polygonsA = window.shapeToPolygons( new phet.kite.Shape( shapeAData ) ).map( subpath => subpath.map( point => {
        return phet.dot.v2( 15 * ( point.x + 0 ) + 20, 15 * ( point.y + 37 ) + 20 ).timesScalar( 0.5 );
      } ) );
      const polygonsB = window.shapeToPolygons( new phet.kite.Shape( shapeBData ) ).map( subpath => subpath.map( point => {
        return phet.dot.v2( point.x + 20, point.y + 20 ).timesScalar( 0.5 );
      } ) );

      const pathA = new RenderPath( 'nonzero', polygonsA );
      const pathB = new RenderPath( 'nonzero', polygonsB );

      const overlaps = PolygonalBoolean.getOverlaps( pathA, pathB );

      scene.addChild( new Path( LinearEdge.polygonsToShape( overlaps.intersection ), {
        fill: 'rgba(0,0,255,0.5)'
      } ) );
      scene.addChild( new Path( LinearEdge.polygonsToShape( overlaps.aOnly ), {
        fill: 'rgba(255,0,0,0.5)'
      } ) );
      scene.addChild( new Path( LinearEdge.polygonsToShape( overlaps.bOnly ), {
        fill: 'rgba(0,255,0,0.5)'
      } ) );
      scene.addChild( new Path( LinearEdge.polygonsToShape( polygonsA ), {
        stroke: 'red'
      } ) );
      scene.addChild( new Path( LinearEdge.polygonsToShape( polygonsB ), {
        stroke: 'green'
      } ) );

      console.log( scene.bounds );

      window.addDiagram( 'boolean-operations-example', () => window.createSceneryDiagram(
        scene,
        340, 300
      ) );
    </script>

    <p class="TODO">
      Extend this to other segment types.
    </p>

    <p class="TODO">
      Local rationals! Dont worry about approximate intersections. Just catch all intersections of rationalization
      within zones where curves are close. Just get rational T values, points, tangents (the slopes of the rationalized
      curves). We will be within epsilons anyway. Just act like the rational intersection is on it (for our
      rasterization purposes). Only rationalize the intersected areas. Rational endpoints, rational intersections,
      rational parameterization.
    </p>

    <p class="TODO">
      Can we find a class of curves that has rational intersections only?
    </p>

    <p class="TODO">
      Review Wildberger book, see rational parametrizations of conics/circle. (Rational trigonometry?)
    </p>

    <h3 id="antialiasing">Anti-Aliasing</h3>

    <h4 id="antialiasing-integrals">Integrals</h4>

    <p>
      This will delve into some of the mathematics and background information behind the anti-aliasing techniques used
      in Alpenglow. Most of the anti-aliasing is based on being able to clip polygons down to pixel boundaries, and then
      integrating the polygonal coverage over the pixel.
    </p>

    <h5>Green's Theorem and Polygons</h5>

    <p>
      Using <a href="https://en.wikipedia.org/wiki/Green%27s_theorem">Green's Theorem</a>, we can convert a double
      integral over a region into a line integral over the (closed, oriented counter-clockwise) boundary of the region:
    </p>

    <p>
      $$
      \oint_P\left(L\,\frac{dx}{dt}+M\,\frac{dy}{dt}\right)dt=\iint_P \left( \frac{\partial M}{\partial x}-\frac{\partial L}{\partial y} \right)\,dx\,dy
      $$
    </p>

    <p>
      for curves parameterized on $t$.
    </p>

    <p>
      For polygons, this means that if we can evaluate a line integral over each line segment (between $(x_i,y_i)$ and
      $(x_{i+1},y_{i+1})$, finishing with $(x_i,y_i)$ to $(x_0,y_0)$), we can sum up each edge's contribution to
      evaluate the double integral for the region inside the polygon. Each line segment is parameterized curve:
    </p>

    <p>

    </p>
      $$
      x=x(t)=(1-t)x_i+(t)x_{i+1}=x_i+t(x_{i+1}-x_i)
      $$

      $$
      y=y(t)=(1-t)y_i+(t)y_{i+1}=y_i+t(y_{i+1}-y_i)
      $$

      for $0 \le t \le 1$, with the derivatives:

      $$
      \frac{dx}{dt}=x_{i+1}-x_i
      $$

      $$
      \frac{dy}{dt}=y_{i+1}-y_i
      $$

      Note:
    </p>

    <ol>
      <li>
        If we reverse an edge (swap its endpoints), it will swap the sign of the contribution to the integral (a polygon
        can make a degenerate turn and double-back precisely, with no contribution to area). Thus for terms, swapping $i$
        and $i+1$ will swap the sign of the contribution. This means that polygons with holes can be evaluated by
        visiting the holes with the opposite orientation (clockwise).
      </li>
      <li>
        This is evaluated on closed polygons, so any terms that only depend on one endpoint will cancel out (e.g.
        $x_i^2y_i$ and $-x_{i+1}^2y_{i+1}$ will have their contributions cancel out, since both of those will be
        evaluated for every point in the polygon). It is useful to adjust the coefficients to these terms, since they
        can allow us to factor the expressions into simpler forms (e.g. the Shoelace formula below).
      </li>
    </ol>

    <p>
      We can pick $L$ and $M$ below:

      $$
      L=(n-1)\int f\,dy
      $$

      $$
      M=(n)\int f\,dx
      $$

      so that

      $$
      \iint_P \left( \frac{\partial M}{\partial x}-\frac{\partial L}{\partial y} \right)\,dx\,dy=
      \iint_P \left( (n)f - (n-1)f \right)\,dx\,dy=
      \iint_P f\,dx\,dy
      $$

      for any antiderivatives and real $n$, since the double integral will then be integrating our function $f$. It turns
      out, evaluating Green's Theorem over line segments for polynomial terms for any linear blend (any $n$) of $L$ and
      $M$ will differ only in the "canceled out" terms, so each edge's contribution will be the same.
    </p>

    <h5>Integrating Arbitrary Polynomials over Polygons</h5>

    <p>
      If we zero out all of the canceled terms, it turns out that we can evaluate the integral of any polynomial term $x^my^n$ over a polygon $P$ by summing up the contributions of each edge:

      $$
      \iint_Px^my^n\,dx\,dy=\frac{m!n!}{(m+n+2)!}\sum_{i}\left[ (x_iy_{i+1}-x_{i+1}y_i) \sum_{p=0}^m\sum_{q=0}^n \binom{p+q}{q}\binom{m+n-p-q}{n-q}x_i^{m-p}x_{i+1}^py_i^{n-q}y_{i+1}^q \right]
      $$

      This was first discovered by Soerjadi (1968) in
      <a href="https://repository.tudelft.nl/islandora/object/uuid:963296a1-8940-4439-9404-eca1bd2f8638/datastream/OBJ/download">On the Computation of the Moments of a Polygon, with some Applications</a>.
      The contributions of each term can be summed up individually to integrate arbitrary polynomials.
    </p>

    <p>
      e.g. for $x^4y^2$ in matrix form:

      $$
      \iint_Px^4y^2\,dx\,dy=
      \frac{1}{840}
      \sum_{i}
      \left(
      (x_iy_{i+1}-x_{i+1}y_i)
      \begin{bmatrix}
      x_i^4 & x_i^3x_{i+1} & x_i^2x_{i+1}^2 & x_ix_{i+1}^3 & x_{i+1}^4
      \end{bmatrix}
      \begin{bmatrix}
      15 & 5 & 1\\
      10 & 8 & 3\\
      6 & 9 & 6\\
      3 & 8 & 10\\
      1 & 5 & 15
      \end{bmatrix}
      \begin{bmatrix}
      y_i^2\\
      y_iy_{i+1}\\
      y_{i+1}^2
      \end{bmatrix}
      \right)
      $$
    </p>

    <h5>Area of Polygons</h5>

    <p>
      For $x^0y^0=1$, with adding some canceling terms to better factor, we'll obtain the
      <a href="https://en.wikipedia.org/wiki/Shoelace_formula">Shoelace formula</a> for finding the area of a polygon:

      $$
      area_P=\iint_P1\,dx\,dy=
      \frac{1}{2}
      \sum_{i}
      (x_i+x_{i+1})(y_{i+1}-y_i)
      $$
    </p>

    <h5>Centroids of Polygons</h5>

    <p>
      <strong>NOTE: see numerical stability notes below, this top way can be inaccurate with floating-point numbers</strong>
    </p>

    <p>
      For $x$ and $y$, we have:

      $$
      \iint_Px\,dx\,dy=
      \frac{1}{6} \sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i+x_{i+1})
      $$

      $$
      \iint_Py\,dx\,dy=
      \frac{1}{6} \sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(y_i+y_{i+1})
      $$

      We can divide the integrals of $x$ and $y$ by the area to get the centroid of the polygon:

      $$
      centroid_x=
      \frac{1}{3}
      \frac{\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i+x_{i+1})}{\sum_{i}(x_i+x_{i+1})(y_{i+1}-y_i)}
      $$

      $$
      centroid_y=
      \frac{1}{3}
      \frac{\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(y_i+y_{i+1})}{\sum_{i}(x_i+x_{i+1})(y_{i+1}-y_i)}
      $$

      This is particularly useful, since if we have any linear function over $(x,y)$ (say, a linear gradient between
      two colors), the average color in the polygon would be the value of that function at the centroid!
    </p>

    <h5>Numerical Stability (addendum)</h5>

    <p>
      The above formulas (from <a href="https://leancrew.com/all-this/2018/01/greens-theorem-and-section-properties/">this reference</a>)
      seem to magnify floating-point error significantly. It's highly recommended that either of the following methods
      be used for computation:
    </p>

    <p>
      For the highest precision (but for which there is not as much shared computation between the $x$ and $y$ formulas),
      we can use the following:

      $$
      \iint_Px\,dx\,dy
      =\frac{1}{6}\sum_{i}(x_i^2 + x_i x_{i+1} + x_{i+1}^2) (y_{i+1} - y_i)
      $$

      $$
      \iint_Py\,dx\,dy
      =\frac{1}{6}\sum_{i}(y_i^2 + y_i y_{i+1} + y_{i+1}^2) (x_i - x_{i+1})
      $$

      For higher performance (but with about 30% more numerical error), one with more shared computation can be used:

      $$
      \iint_Px\,dx\,dy
      =\frac{1}{6}\sum_{i}(x_i-x_{i+1})(x_i(2y_i+y_{i+1}) + x_{i+1}(y_i+2y_{i_1}))
      $$

      $$
      \iint_Py\,dx\,dy
      =\frac{1}{6}\sum_{i}(y_{i+1}-y_i)(x_i(2y_i+y_{i+1}) + x_{i+1}(y_i+2y_{i_1}))
      $$

      Both of these approaches are incredibly more stable than the first formula pair (about half a million times less
      error, with triangles centered in x,y in (0,1000), with sizes around 1/1000).

    </p>

    <p>
      For example, with p0={x: 716.1014074033982, y: 879.8148178803798}, p1={x: 716.1017435139888, y: 879.8150887077004},
      p2={x: 716.1021422611582, y: 879.8154096593055}. The top method gives {x: 238.700559480381, y: 293.2716129164566}
      (! distance of more than 700 from the real centroid), whereas the error (distance) for the other methods are
      less than 1e-3

    </p>

    <h5>Evaluation of Filtered Polygons</h5>

    <p>
      Any polynomial-based (windowed or not) filter can be evaluated over a polygon with this approach.
    </p>

    <p>
      A simple practical example is the tent filter (for <a href="https://en.wikipedia.org/wiki/Bilinear_interpolation">Bilinear filtering</a>).
      It is effectively evaluating the integral $(1-x)(1-y)=xy-x-y+1$ over $0\le x\le1,0\le y\le1$, which we can now
      evaluate as:

      $$
      \frac{1}{24}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(12-4( x_i+y_i+x_{i+1}+y_{i+1})+2(x_iy_i+x_{i+1}y_{i+1})+
      x_iy_{i+1}+x_{i+1}y_i)
      $$
    </p>

    <h5>Evaluation of Distance over Polygons</h5>

    <p>
      Above, we saw the centroid is useful to compute exact linear gradient contributions. For purely-circular radial gradients, the equivalent is also possible to compute! We'll need to instead integrate $r=\sqrt{x^2+y^2}$ (we can determine the average by dividing by the area).
    </p>

    <p>
      We'll need to transform to polar coordinates first:

      $$
      r=\sqrt{x^2+y^2}
      $$

      $$
      \theta=\tan^{-1}\frac{y}{x}
      $$

      We'll want to evaluate with Green's Theorem in polar coordinates:

      $$
      \oint_P\left(L\,\frac{dr}{dt}+M\,\frac{d\theta}{dt}\right)dt=\iint_P \left( \frac{\partial M}{\partial r}-\frac{\partial L}{\partial \theta} \right)\,dA
      $$

      but we'll want to evaluate $r^2$ due to the coordinate change.
    </p>

    <p>
      If we pick $M=\frac{1}{3}r^3$ and $L=0$, the double integral will be our desired integral (note, $M=\frac{1}{2}r^2$ gives us the same Shoelace-like area formula).
    </p>

    <p>
      Given our definitions of $x=x_i+t(x_{i+1}-x_i)$ and $y=y_i+t(y_{i+1}-y_i)$:

      $$
      \begin{aligned}
      \frac{d\theta}{dt}&=\frac{d}{dt}\tan^{-1}\frac{y}{x} \\
      &=\frac{d}{dt}\tan^{-1}\frac{y_i+t(y_{i+1}-y_i)}{x_i+t(x_{i+1}-x_i)} \\
      &=\frac{x_iy_{i+1}-x_{i+1}y_i}{t^2((x_{i_1}-x_i)^2+(y_{i+1}-y_i)^2)-2t(x_i^2-x_ix_{i+1}-y_iy_{i+1}+y_i^2)+(x_i^2+y_i^2)}
      \end{aligned}
      $$

      Thus given $M$ and $\frac{d\theta}{dt}$, we can evaluate (with Mathematica in this case):

      $$
      \begin{aligned}
      \oint_P\left(M\,\frac{d\theta}{dt}\right)dt&=\int_0^1\frac{1}{3}r^3\frac{d\theta}{dt}\,dt \\
      &=
      \frac{s}{6d_{xy}^3}\left[
        d_{xy}\left( q_0( x_i^2 - x_ix_{i+1} - y_id_y ) + q_1( k_x + y_{i+1}d_y ) \right) +
        s^2\log\frac{k_x + k_y + d_{xy}q_1}{x_id_x + q_0d_{xy} + y_id_y}
      \right]
      \end{aligned}
      $$

      with

      $$d_x = x_{i+1} - x_i$$

      $$d_y = y_{i+1} - y_i$$

      $$s = x_iy_{i+1} - y_ix_{i+1}$$

      $$d_{xy} = \sqrt{d_xd_x + d_yd_y}$$

      $$q_0 = \sqrt{x_ix_i + y_iy_i}$$

      $$q_1 = \sqrt{x_{i+1}x_{i+1} + y_{i+1}y_{i+1}}$$

      $$k_x = x_{i+1}x_{i+1} - x_ix_{i+1}$$

      $$k_y = y_{i+1}y_{i+1} - y_iy_{i+1}$$

      thus

      $$
      \iint_P\sqrt{x^2+y^2}\,dx\,dy=
      \frac{s}{6d_{xy}^3}\left[
        d_{xy}\left( q_0( x_i^2 - x_ix_{i+1} - y_id_y ) + q_1( k_x + y_{i+1}d_y ) \right) +
        s^2\log\frac{k_x + k_y + d_{xy}q_1}{x_id_x + q_0d_{xy} + y_id_y}
      \right]
      $$
    </p>

    <h5>Checking if a Polygon is not Closed</h5>

    <p>
      We can integrate $0$ over a polygon's edges in a similar way, to compute if the polygon is not closed (there are some cases where this happens and is useful).

      $$
      0=\sum_{i}(x_iy_i-x_{i+1}y_{i+1})
      $$

      This test (and any other tests of this type) will have false-negatives (for instance, if all the points are on an x or y axis, this formula won't detect non-closed polygons). However the useful probability of that happening can be reduced by using a random point as a translation:

      $$
      0=\sum_{i}\left[(x_i-p_x)(y_i-p_y)-(x_{i+1}-p_x)(y_{i+1}-p_y)\right]
      $$
    </p>

    <h5>Assorted formulas</h5>

    <p>
      Cases where we can adjust the formulas for integrals that might be useful

      $
      \iint_P1\,dx\,dy
      =\frac{1}{2}\sum_{i}(x_i+x_{i+1})(y_{i+1}-y_i)
      =\frac{1}{2}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)
      =\frac{1}{2}\sum_{i}(y_i+y_{i+1})(x_i-x_{i+1})
      $

      $
      \iint_Px\,dx\,dy
      =\frac{1}{6}\sum_{i}(x_i + x_{i+1}) (x_i y_{i+1}-y_i x_{i+1})
      =\frac{1}{6}\sum_{i}(x_i^2 + x_i x_{i+1} + x_{i+1}^2) (y_{i+1} - y_i)
      =\frac{1}{6}\sum_{i}(x_i-x_{i+1})(x_i(2y_i+y_{i+1}) + x_{i+1}(y_i+2y_{i_1}))
      $

      $
      \iint_Py\,dx\,dy
      =\frac{1}{6}\sum_{i}(y_i + y_{i+1}) (x_i y_{i+1} - y_i x_{i+1})
      =\frac{1}{6}\sum_{i}(y_i^2 + y_i y_{i+1} + y_{i+1}^2) (x_i - x_{i+1})
      =\frac{1}{6}\sum_{i}(y_{i+1}-y_i)(x_i(2y_i+y_{i+1}) + x_{i+1}(y_i+2y_{i_1}))
      $

      $
      \iint_Px^2\,dx\,dy
      =\frac{1}{12}\sum_{i}(x_i + x_{i+1}) (x_i^2 + x_{i+1}^2) (y_{i+1} - y_i)
      =\frac{1}{12}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i^2 + x_i x_{i+1} + x_{i+1}^2)
      $

      $
      \iint_Pxy\,dx\,dy
      =\frac{1}{24}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i (2 y_i + y_{i+1}) + x_{i+1} (y_i + 2 y_{i+1}))
      $

      $
      \iint_Py^2\,dx\,dy
      =\frac{1}{12}\sum_{i}(y_i + y_{i+1})(y_i^2 + y_{i+1}^2)(x_i - x_{i+1})
      =\frac{1}{12}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(y_i^2 + y_i y_{i+1} + y_{i+1}^2)
      $

      Additionally, powers of $x^m$ or $y^n$ on their own show a prime-factorization-like pattern when factored:

      $\iint_Px^0\,dx\,dy=\frac{1}{2}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)$
      $\iint_Px^1\,dx\,dy=\frac{1}{6}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i + x_{i+1})$
      $\iint_Px^2\,dx\,dy=\frac{1}{12}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i^2 + x_i x_{i+1} + x_{i+1}^2)$
      $\iint_Px^3\,dx\,dy=\frac{1}{20}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i + x_{i+1}) (x_i^2 + x_{i+1}^2)$
      $\iint_Px^4\,dx\,dy=\frac{1}{30}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i^4 + x_i^3 x_{i+1} + x_i^2 x_{i+1}^2 + x_i x_{i+1}^3 + x_{i+1}^4)$
      $\iint_Px^5\,dx\,dy=\frac{1}{42}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i + x_{i+1}) (x_i^2 - x_i x_{i+1} + x_{i+1}^2) (x_i^2 + x_i x_{i+1} + x_{i+1}^2)$
      $\iint_Px^6\,dx\,dy=\frac{1}{56}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i^6 + x_i^5 x_{i+1} + x_i^4 x_{i+1}^2 + x_i^3 x_{i+1}^3 + x_i^2 x_{i+1}^4 +
        x_i x_{i+1}^5 + x_{i+1}^6)$
      $\iint_Px^7\,dx\,dy=\frac{1}{72}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i + x_{i+1}) (x_i^2 + x_{i+1}^2) (x_i^4 + x_{i+1}^4)$
      $\iint_Px^8\,dx\,dy=\frac{1}{90}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i^2 + x_i x_{i+1} + x_{i+1}^2) (x_i^6 + x_i^3 x_{i+1}^3 + x_{i+1}^6)$
      $\iint_Px^9\,dx\,dy=\frac{1}{110}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i + x_{i+1}) (x_i^4 - x_i^3 x_{i+1} + x_i^2 x_{i+1}^2 - x_i x_{i+1}^3 +
         x_{i+1}^4) (x_i^4 + x_i^3 x_{i+1} + x_i^2 x_{i+1}^2 + x_i x_{i+1}^3 + x_{i+1}^4)$
      $\iint_Px^{10}\,dx\,dy=\frac{1}{132}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i^10 + x_i^9 x_{i+1} + x_i^8 x_{i+1}^2 + x_i^7 x_{i+1}^3 + x_i^6 x_{i+1}^4 +
        x_i^5 x_{i+1}^5 + x_i^4 x_{i+1}^6 + x_i^3 x_{i+1}^7 + x_i^2 x_{i+1}^8 + x_i x_{i+1}^9 +
        x_{i+1}^10) $

      So some powers are more efficient to evaluate than others:

      $\iint_Px^{128-1}\,dx\,dy=\frac{1}{16512}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i + x_{i+1})(x_i^2 + x_{i+1}^2)(x_i^4 + x_{i+1}^4)(x_i^8 + x_{i+1}^8)(x_i^16 + x_{i+1}^16)(x_i^32 + x_{i+1}^32)(x_i^64 + x_{i+1}^64)$
      $\iint_Px^{81-1}\,dx\,dy=\frac{1}{6642}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(x_i^{2}+x_ix_{i+1}+x_{i+1}^{2})(x_i^{6}+x_i^{3}x_{i+1}^{3}+x_{i+1}^{6})(x_i^{18}+x_i^{9}x_{i+1}^{9}+x_{i+1}^{18})(x_i^{54}+x_i^{27}x_{i+1}^{27}+x_{i+1}^{54})$
    </p>

    <p class="TODO">
      Note "ability to skip horizontal edges" in math doc. Can formulate area/centroid/bilinear to all ignore horizontals.
      We can prove alternative formulas based off of Soefredi and the "opposing variable terms"
    </p>

    <h5>Alpenglow Area Formulas</h5>

    <p>
      We're best served by the Shoelace formula. It is fast and has good numerical performance:
    </p>

    <p>
      $$
      area=
      \frac{1}{2}
      \sum_{i}
      (x_i+x_{i+1})(y_{i+1}-y_i)
      $$

      For our edge-clipped polygons, we'll want to add in the contribution of the counts:

      $$
      area_{clip} = ( y_{max} - y_{min} )( count_{x_{min}} x_{min} + count_{x_{max}} x_{max} )
      $$

      NOTE that it only uses two of the counts! We can't abuse this too much, because for recursive clipping we still
      need to store the opposite counts.
    </p>

    <h5>Alpenglow Centroid Formulas</h5>

    <p>
      As noted above, some of the more common formulas have terrible numerical performance. We're using the following
      one, since it results in simple formulas for the normal and edge-clipped cases, AND it shares a good amount of
      the computation between the $x$ and $y$ formulas:
    </p>

    <p>
      $$
      centroid =
      \frac{1}{6\ area}
      \sum_{i}
      \left( x_i ( 2 y_i + y_{i+1} ) + x_{i+1} ( y_i + 2 y_{i+1} ) \right)
      \begin{bmatrix}
      x_i - x_{i+1} \\ y_{i+1} - y_i
      \end{bmatrix}
      $$

      Additionally for our edge-clipped polygons, we'll want to add the contribution based on the counts:

      $$
      centroid_{clip} =
      \frac{1}{area}
      \begin{bmatrix}
      x_{avg} ( x_{min} - x_{max} ) * ( count_{y_{min}} * y_{min} + count_{y_{max}} * y_{max} ) \\
      y_{avg} ( y_{max} - y_{min} ) * ( count_{x_{min}} * x_{min} + count_{x_{max}} * x_{max} )
      \end{bmatrix}
      $$

      Where $x_{avg}=\frac{1}{2}(x_{min}+x_{max})$ and $y_{avg}=\frac{1}{2}(y_{min}+y_{max})$ are the values of the
      center of the edge-clipped area.
    </p>

    <h4 id="antialiasing-filters">Filters</h4>
    <!-- For antialiasing-->

    <p>
      For each filter, we're going to evaluate it at a pixel's "center" to get a single sample. We'll do this by
      evaluating the integral of the filter's value over the area included in the polygon within the filter's range of
      support.
    </p>

    <p>
      Below, we're able to evaluate piecewise-polynomial filters with an exact analytical solution. While the box filter
      has one piecewise-polynomial section (the constant function), the others are split up into gridded sections,
      each of which is a polynomial. We will essentially determine the clipped part of the polygon for each section,
      and evaluate the integral with the formula for that section.
    </p>

    <p>
      NOTE: When using a non-box filter, we'll need to examine/process a larger area than just the resulting bounds.
      In the code, this is called the <code>contributionBounds</code>.
    </p>

    <h5>Box Filter</h5>

    <div class="example">
      <div id="box-diagram"></div>
    </div>

    <p>
      We'll take our filter (which is a constant function of 1 in a unit-square centered on the origin), and evaluate
      it just for the square area around it. This is equivalent to finding the area of the polygon within this square area.
    </p>

    <h5>Bilinear Filter</h5>

    <div class="example">
      <div id="bilinear-diagram"></div>
    </div>

    <p>
      Bilinear filtering uses the tent filter $f(t) = |1-t|$ for $t \in [-1,1]$, but extended to 2D:
      $f(x,y) = |1-x| |1-y|$. Thus it has four quadrants, each of which is polynomial. We can evaluate the integral for
      the edges of the clipped polygon within each of these quadrants with the formula:

      $$
      \frac{1}{24}\sum_{i}(x_iy_{i+1}-x_{i+1}y_i)(12-4( x_i+y_i+x_{i+1}+y_{i+1})+2(x_iy_i+x_{i+1}y_{i+1})+
      x_iy_{i+1}+x_{i+1}y_i)
      $$

      We can simply take the absolute value of the relative $x$ and $y$ values, and use the same formula for all
      quadrants.
    </p>

    <h5>Mitchell-Netravali Filter</h5>

    <div class="example">
      <div id="mitchell-netravali-diagram"></div>
    </div>

    <p>
      The Mitchell-Netravali filter (really a class of filters, where we use the common parameter values $B=1/3$ and $C=1/3$)
      is a piecewise-polynomial filter. Notably:

      $$
      f(t)=
      \begin{cases}
			  |t|<1, & \frac{1}{6}((12 - 9B - 6C)t^3 + (-18 + 12B + 6C)t^2 + (6 - 2B)) \\
        1\le |t| < 2, & \frac{1}{6}((-B - 6C)t^3 + (6B + 30C)t^2 + (-12B - 48C) t + (8B + 24C))
		  \end{cases}

      $$

      We'll use the above polynomial filtering techniques to evaluate the integral. The resulting formulas are not
      terribly pretty. We'll have 3 cases to handle after symmetry (we can use the absolute value to get down to 4
      cases, and then reflection to get down to 3).
    </p>

    <p>
      Note that this filter also has sections where it goes negative, so it can actually cause negative values.
      We try not to clamp color values until the very end (during gamut mapping), so that this effect will work nicely.
    </p>

    <p>
      It will result in 16 different sections, each of which will contribute to a final output sample (pixel).
    </p>

    <script type="module">
      import { Node, Path, Text, Image, Circle } from '../../chipper/dist/js/scenery/js/imports.js';
      import { Shape } from '../../chipper/dist/js/kite/js/imports.js';
      import dot from '../../chipper/dist/js/dot/js/dot.js';
      const Matrix3 = dot.Matrix3;
      const Bounds2 = dot.Bounds2;
      const v2 = dot.v2;
      // TODO: show shape of filter
      // TODO: left diagram shows the polygon over a pixel grid. shows the clipped versions of it (strokes)
      // TODO: arrow between
      // TODO: right diagram shows the box-filtered version (for each pixel)

      const size = 200;
      const padding = 4;

      const scale3 = ( size - 2 * padding ) / 3;
      const scale5 = ( size - 2 * padding ) / 5;

      const matrix3 = Matrix3.translation( padding + scale3, padding + scale3 ).timesMatrix( Matrix3.scaling( scale3 ) );
      const matrix5 = Matrix3.translation( padding + 2 * scale5, padding + 2 * scale5 ).timesMatrix( Matrix3.scaling( scale5 ) );

      const shape = new Shape()
        .moveTo( -2, -1 )
        .lineTo( -0.7, -0.5 )
        .lineTo( 0.8, 1.4 )
        .lineTo( 0.3, -0.7 )
        .lineTo( 2.4, 0.5 )
        .lineTo( 3, 2 )
        .lineTo( 3, 3 )
        .lineTo( -2, 3 )
        .close();
      const shape3 = shape.shapeIntersection( Shape.bounds( new Bounds2( -1, -1, 2, 2 ) ) );
      const shape5 = shape.shapeIntersection( Shape.bounds( new Bounds2( -2, -2, 3, 3 ) ) );

      const createGridShape = ( minX, minY, maxX, maxY ) => {
        const gridShape = new Shape();
        for ( let i = minX; i <= maxX; i++ ) {
          gridShape.moveToPoint( v2( i, minY ) );
          gridShape.lineToPoint( v2( i, maxY ) );
        }
        for ( let i = minY; i <= maxY; i++ ) {
          gridShape.moveToPoint( v2( minX, i ) );
          gridShape.lineToPoint( v2( maxX, i ) );
        }
        return gridShape;
      };

      const grid3Node = new Path( createGridShape( -1, -1, 2, 2 ).transformed( matrix3 ), {
        stroke: 'black',
        lineWidth: 0.5,
        lineDash: [ 2, 2 ]
      } );
      const grid5Node = new Path( createGridShape( -2, -2, 3, 3 ).transformed( matrix5 ), {
        stroke: 'black',
        lineWidth: 0.5,
        lineDash: [ 2, 2 ]
      } );

      const fill3Node = new Path( shape3.transformed( matrix3 ), {
        fill: 'rgba(255,0,0,0.7)'
      } );

      const fill5Node = new Path( shape5.transformed( matrix5 ), {
        fill: 'rgba(255,0,0,0.7)'
      } );

      const stroke3Node = new Path( shape3.transformed( matrix3 ), {
        stroke: 'rgba(60,0,0,0.3)'
      } );

      const stroke5Node = new Path( shape5.transformed( matrix5 ), {
        stroke: 'rgba(60,0,0,0.3)'
      } );

      const samples3Node = new Node( {
        children: [
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( -0.5, -0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( 0.5, -0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( 1.5, -0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( -0.5, 0.5 ) ) } ),
          new Circle( 2, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( 0.5, 0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( 1.5, 0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( -0.5, 1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( 0.5, 1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix3.timesVector2( v2( 1.5, 1.5 ) ) } )
        ]
      } );

      const samples5Node = new Node( {
        children: [
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -1.5, -1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -0.5, -1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 0.5, -1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 1.5, -1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 2.5, -1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -1.5, -0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -0.5, -0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 0.5, -0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 1.5, -0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 2.5, -0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -1.5, 0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -0.5, 0.5 ) ) } ),
          new Circle( 2, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 0.5, 0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 1.5, 0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 2.5, 0.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -1.5, 1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -0.5, 1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 0.5, 1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 1.5, 1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 2.5, 1.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -1.5, 2.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( -0.5, 2.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 0.5, 2.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 1.5, 2.5 ) ) } ),
          new Circle( 1, { fill: 'rgb(0,100,100)', translation: matrix5.timesVector2( v2( 2.5, 2.5 ) ) } )
        ]
      } );

      const boxFilter3Node = new Path( Shape.bounds( new Bounds2( 0, 0, 1, 1 ) ).transformed( matrix3 ), {
        fill: 'rgba(0,100,100,0.7)',
        stroke: 'black',
        lineWidth: 1
      } );

      const boxFilterIntersection3Node = new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 0, 0, 1, 1 ) ) ).transformed( matrix3 ), {
        fill: 'rgba(255,0,0,1)',
        stroke: 'black'
      } );

      const bilinearResolution = 256;
      const bilinearFilterImageData = new ImageData( bilinearResolution, bilinearResolution );
      const bilinearFilterIntersectionImageData = new ImageData( bilinearResolution, bilinearResolution );
      for ( let i = 0; i < bilinearResolution; i++ ) {
        const y = 2 * ( i - ( bilinearResolution - 1 ) / 2 ) / bilinearResolution;
        for ( let j = 0; j < bilinearResolution; j++ ) {
          const x = 2 * ( j - ( bilinearResolution - 1 ) / 2 ) / bilinearResolution;

          const value = ( 1 - Math.abs( x ) ) * ( 1 - Math.abs( y ) );
          bilinearFilterImageData.data[ 4 * ( i * bilinearResolution + j ) ] = 0;
          bilinearFilterImageData.data[ 4 * ( i * bilinearResolution + j ) + 1 ] = 100;
          bilinearFilterImageData.data[ 4 * ( i * bilinearResolution + j ) + 2 ] = 100;
          bilinearFilterImageData.data[ 4 * ( i * bilinearResolution + j ) + 3 ] = 255 * Math.pow( value, 1 / 1.5 );

          const intersects = shape.containsPoint( v2( x + 0.5, y + 0.5 ) );
          const intersectedValue = intersects ? value : 0;
          bilinearFilterIntersectionImageData.data[ 4 * ( i * bilinearResolution + j ) ] = 255;
          bilinearFilterIntersectionImageData.data[ 4 * ( i * bilinearResolution + j ) + 1 ] = 0;
          bilinearFilterIntersectionImageData.data[ 4 * ( i * bilinearResolution + j ) + 2 ] = 0;
          bilinearFilterIntersectionImageData.data[ 4 * ( i * bilinearResolution + j ) + 3 ] = 255 * Math.pow( intersectedValue, 1 / 1.5 );
        }
      }
      const bilinearFilterCanvas = document.createElement( 'canvas' );
      bilinearFilterCanvas.width = bilinearResolution;
      bilinearFilterCanvas.height = bilinearResolution;
      bilinearFilterCanvas.getContext( '2d' ).putImageData( bilinearFilterImageData, 0, 0 );
      const bilinearFilterIntersectionCanvas = document.createElement( 'canvas' );
      bilinearFilterIntersectionCanvas.width = bilinearResolution;
      bilinearFilterIntersectionCanvas.height = bilinearResolution;
      bilinearFilterIntersectionCanvas.getContext( '2d' ).putImageData( bilinearFilterIntersectionImageData, 0, 0 );

      const cubicResolution = 512;
      const cubicFilterImageData = new ImageData( cubicResolution, cubicResolution );
      const cubicFilterIntersectionImageData = new ImageData( cubicResolution, cubicResolution );
      for ( let i = 0; i < cubicResolution; i++ ) {
        const y = 4 * ( i - ( cubicResolution - 1 ) / 2 ) / cubicResolution;
        for ( let j = 0; j < cubicResolution; j++ ) {
          const x = 4 * ( j - ( cubicResolution - 1 ) / 2 ) / cubicResolution;

          // within 1: (1/6)*((12 - 9*b - 6*c)*t^3 + (-18 + 12*b + 6*c)*t^2 + (6 - 2*b))
          // outside 1: (1/6)*((-b - 6*c)*t^3 + (6*b + 30*c)*t^2 + (-12*b - 48*c)*t + (8*b + 24*c))

          const absX = Math.abs( x );
          const absY = Math.abs( y );

          let value = 1;
          value *= absX < 1 ? ( 7 / 6 * absX * absX * absX - 2 * absX * absX + 8 / 9 ) : ( -7 / 18 * absX * absX * absX + 2 * absX * absX - 10 / 3 * absX + 16 / 9 );
          value *= absY < 1 ? ( 7 / 6 * absY * absY * absY - 2 * absY * absY + 8 / 9 ) : ( -7 / 18 * absY * absY * absY + 2 * absY * absY - 10 / 3 * absY + 16 / 9 );

          cubicFilterImageData.data[ 4 * ( i * cubicResolution + j ) ] = value > 0 ? 0 : 255;
          cubicFilterImageData.data[ 4 * ( i * cubicResolution + j ) + 1 ] = value > 0 ? 100 : 0;
          cubicFilterImageData.data[ 4 * ( i * cubicResolution + j ) + 2 ] = value > 0 ? 100 : 0;
          cubicFilterImageData.data[ 4 * ( i * cubicResolution + j ) + 3 ] = 255 * Math.pow( Math.abs( value ), 1 / 1.5 );

          const intersects = shape.containsPoint( v2( x + 0.5, y + 0.5 ) );
          const intersectedValue = intersects ? value : 0;
          cubicFilterIntersectionImageData.data[ 4 * ( i * cubicResolution + j ) ] = intersectedValue > 0 ? 255 : 0;
          cubicFilterIntersectionImageData.data[ 4 * ( i * cubicResolution + j ) + 1 ] = intersectedValue > 0 ? 0 : 255;
          cubicFilterIntersectionImageData.data[ 4 * ( i * cubicResolution + j ) + 2 ] = intersectedValue > 0 ? 0 : 255;
          cubicFilterIntersectionImageData.data[ 4 * ( i * cubicResolution + j ) + 3 ] = 255 * Math.pow( Math.abs( intersectedValue ), 1 / 1.5 );
        }
      }
      const cubicFilterCanvas = document.createElement( 'canvas' );
      cubicFilterCanvas.width = cubicResolution;
      cubicFilterCanvas.height = cubicResolution;
      cubicFilterCanvas.getContext( '2d' ).putImageData( cubicFilterImageData, 0, 0 );
      const cubicFilterIntersectionCanvas = document.createElement( 'canvas' );
      cubicFilterIntersectionCanvas.width = cubicResolution;
      cubicFilterIntersectionCanvas.height = cubicResolution;
      cubicFilterIntersectionCanvas.getContext( '2d' ).putImageData( cubicFilterIntersectionImageData, 0, 0 );

      const bilinearFilter3Node = new Node( {
        children: [
          new Path( createGridShape( -0.5, -0.5, 1.5, 1.5 ).transformed( matrix3 ), {
            stroke: 'black',
            lineWidth: 0.5
          } ),
          new Node( {
            matrix: matrix3,
            children: [
              new Node( {
                x: 0.5,
                y: 0.5,
                scale: 2 / bilinearResolution,
                children: [
                  new Image( bilinearFilterCanvas, {
                    x: -bilinearResolution / 2,
                    y: -bilinearResolution / 2
                  } )
                ]
              } )
            ]
          } )
        ]
      } );

      const bilinearFilterIntersection3Node = new Node( {
        children: [
          new Path( createGridShape( -0.5, -0.5, 1.5, 1.5 ).transformed( matrix3 ), {
            stroke: 'black',
            lineWidth: 0.5,
            opacity: 0.3
          } ),
          new Node( {
            matrix: matrix3,
            children: [
              new Node( {
                x: 0.5,
                y: 0.5,
                scale: 2 / bilinearResolution,
                children: [
                  new Image( bilinearFilterIntersectionCanvas, {
                    x: -bilinearResolution / 2,
                    y: -bilinearResolution / 2
                  } )
                ]
              } )
            ]
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -0.5, -0.5, 0.5, 0.5 ) ) ).transformed( matrix3 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 0.5, -0.5, 1.5, 0.5 ) ) ).transformed( matrix3 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -0.5, 0.5, 0.5, 1.5 ) ) ).transformed( matrix3 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 0.5, 0.5, 1.5, 1.5 ) ) ).transformed( matrix3 ), {
            stroke: 'black'
          } )
        ]
      } );

      const cubicFilter5Node = new Node( {
        children: [
          new Path( createGridShape( -1.5, -1.5, 2.5, 2.5 ).transformed( matrix5 ), {
            stroke: 'black',
            lineWidth: 0.5
          } ),
          new Node( {
            matrix: matrix5,
            children: [
              new Node( {
                x: 0.5,
                y: 0.5,
                scale: 4 / cubicResolution,
                children: [
                  new Image( cubicFilterCanvas, {
                    x: -cubicResolution / 2,
                    y: -cubicResolution / 2
                  } )
                ]
              } )
            ]
          } )
        ]
      } );

      const cubicFilterIntersection5Node = new Node( {
        children: [
          new Path( createGridShape( -1.5, -1.5, 2.5, 2.5 ).transformed( matrix5 ), {
            stroke: 'black',
            lineWidth: 0.5,
            opacity: 0.3
          } ),
          new Node( {
            matrix: matrix5,
            children: [
              new Node( {
                x: 0.5,
                y: 0.5,
                scale: 4 / cubicResolution,
                children: [
                  new Image( cubicFilterIntersectionCanvas, {
                    x: -cubicResolution / 2,
                    y: -cubicResolution / 2
                  } )
                ]
              } )
            ]
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -1.5, -1.5, -0.5, -0.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -0.5, -1.5, 0.5, -0.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 0.5, -1.5, 1.5, -0.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 1.5, -1.5, 2.5, -0.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -1.5, -0.5, -0.5, 0.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -0.5, -0.5, 0.5, 0.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 0.5, -0.5, 1.5, 0.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 1.5, -0.5, 2.5, 0.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -1.5, 0.5, -0.5, 1.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -0.5, 0.5, 0.5, 1.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 0.5, 0.5, 1.5, 1.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 1.5, 0.5, 2.5, 1.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -1.5, 1.5, -0.5, 2.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( -0.5, 1.5, 0.5, 2.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 0.5, 1.5, 1.5, 2.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } ),
          new Path( shape.shapeIntersection( Shape.bounds( new Bounds2( 1.5, 1.5, 2.5, 2.5 ) ) ).transformed( matrix5 ), {
            stroke: 'black'
          } )
        ]
      } );

      const pixelsLabelNode = new Text( 'Pixel Grid', {
        font: '10px sans-serif',
        right: size - 5,
        top: 3,
        fill: '#666'
      } );

      const boxFilterLabel = new Text( 'Box Filter', {
        font: '12px sans-serif',
        centerX: size / 2,
        bottom: size - 5,
        fill: '#333'
      } );

      const bilinearFilterLabel = new Text( 'Bilinear Filter', {
        font: '12px sans-serif',
        centerX: size / 2,
        bottom: size - 5,
        fill: '#333'
      } );

      const cubicFilterLabel = new Text( 'Mitchell-Netravali Filter', {
        font: '12px sans-serif',
        centerX: size / 2,
        bottom: size - 5,
        fill: '#333'
      } );

      const contributionLabel = new Text( 'Contribution (product of both)', {
        font: '12px sans-serif',
        centerX: size / 2,
        bottom: size - 5,
        fill: '#333'
      } );

      const polygonLabel = new Text( 'Input Polygon', {
        font: '12px sans-serif',
        centerX: size / 2,
        bottom: size - 5,
        fill: '#333'
      } );

      window.addDiagram( 'box-diagram', () => window.createSceneryDiagram(
        new Node( {
          children: [
            new Node( {
              children: [
                samples3Node,
                fill3Node,
                grid3Node,
                pixelsLabelNode,
                polygonLabel
              ]
            } ),
            new Node( {
              x: size,
              children: [
                grid3Node,
                boxFilter3Node,
                pixelsLabelNode,
                boxFilterLabel
              ]
            } ),
            new Node( {
              x: 2 * size,
              children: [
                grid3Node,
                stroke3Node,
                boxFilterIntersection3Node,
                pixelsLabelNode,
                contributionLabel
              ]
            } )
          ]
        } ),
        3 * size, size
      ) );

      window.addDiagram( 'bilinear-diagram', () => window.createSceneryDiagram(
        new Node( {
          children: [
            new Node( {
              children: [
                samples3Node,
                fill3Node,
                grid3Node,
                pixelsLabelNode,
                polygonLabel
              ]
            } ),
            new Node( {
              x: size,
              children: [
                grid3Node,
                bilinearFilter3Node,
                pixelsLabelNode,
                bilinearFilterLabel
              ]
            } ),
            new Node( {
              x: 2 * size,
              children: [
                grid3Node,
                stroke3Node,
                bilinearFilterIntersection3Node,
                pixelsLabelNode,
                contributionLabel
              ]
            } )
          ]
        } ),
        3 * size, size
      ) );

      window.addDiagram( 'mitchell-netravali-diagram', () => window.createSceneryDiagram(
        new Node( {
          children: [
            new Node( {
              children: [
                samples5Node,
                fill5Node,
                grid5Node,
                pixelsLabelNode,
                polygonLabel
              ]
            } ),
            new Node( {
              x: size,
              children: [
                grid5Node,
                cubicFilter5Node,
                pixelsLabelNode,
                cubicFilterLabel
              ]
            } ),
            new Node( {
              x: 2 * size,
              children: [
                grid5Node,
                stroke5Node,
                cubicFilterIntersection5Node,
                pixelsLabelNode,
                contributionLabel
              ]
            } )
          ]
        } ),
        3 * size, size
      ) );
    </script>

    <h4 id="antialiasing-examples">Examples</h4>

    <p>
      Aliasing (what we're trying to avoid) is the low-frequency pattern that spuriously appears when we display
      high-frequency content in a low-resolution way. In general, we want to reduce these low-frequency patterns
      without overly introducing blurring.
    </p>

    <h5>Checkerboards</h5>

    <p>
      Checkerboard with 3d perspective has a smooth transition from low to high frequency. Note that the pattern
      should blur to gray as it fades in the distance. Visible patterns are a sign of aliasing.
    </p>

    <div class="row-fluid" style="margin-bottom: 15px;">
      <div class="span2"></div>
      <div class="span4 example">
        <div id="checkerboard-canvas"></div>
        Canvas
      </div>
      <div class="span4 example">
        <div id="checkerboard-svg"></div>
        SVG
      </div>
      <div class="span2"></div>
    </div>

    <div class="row-fluid" style="margin-bottom: 15px;">
      <div class="span4 example">
        <div id="checkerboard-box"></div>
        Box Filter
      </div>
      <div class="span4 example">
        <div id="checkerboard-bilinear"></div>
        Bilinear Filter
      </div>
      <div class="span4 example">
        <div id="checkerboard-mitchell-netravali"></div>
        Mitchell-Netravali Filter
      </div>
    </div>

    <h5>Siemens Stars</h5>

    <p>
      Siemens stars can show Moir patterns.
    </p>

    <div class="row-fluid" style="margin-bottom: 15px;">
      <div class="span2"></div>
      <div class="span4 example">
        <div id="siemens-canvas"></div>
        Canvas
      </div>
      <div class="span4 example">
        <div id="siemens-svg"></div>
        SVG
      </div>
      <div class="span2"></div>
    </div>

    <div class="row-fluid" style="margin-bottom: 15px;">
      <div class="span4 example">
        <div id="siemens-box"></div>
        Box Filter
      </div>
      <div class="span4 example">
        <div id="siemens-bilinear"></div>
        Bilinear Filter
      </div>
      <div class="span4 example">
        <div id="siemens-mitchell-netravali"></div>
        Mitchell-Netravali Filter
      </div>
    </div>

    <h5>Blurs</h5>

    <p>
      If we artificially scale the filter (possible in Alpenglow software, but not planned for GPU), it's possible to
      generate blurs.
    </p>


    <div class="row-fluid" style="margin-bottom: 15px;">
      <div class="span6 example">
        <div id="blur-reference"></div>
        Reference (Dirac Delta)
      </div>
      <div class="span6 example">
        <div id="blur-box"></div>
        Box Filter
      </div>
    </div>

    <div class="row-fluid" style="margin-bottom: 15px;">
      <div class="span6 example">
        <div id="blur-bilinear"></div>
        Bilinear Filter
      </div>
      <div class="span6 example">
        <div id="blur-mitchell-netravali"></div>
        Mitchell-Netravali Filter
      </div>
    </div>

    <p class="DEFERRED">Polynomial approximation to lanczos filter would be great</p>

    <p class="DEFERRED">
      Unsharp masking would be great with the "overblurring" (scaling the filter up). Is there a way to create a
      <code>RenderBlur</code> in any reasonable fashion? This would need... multiple levels of Alpenglow reduction?
      (Would sharpen the oklab luminosity channel)
    </p>

    <p class="DEFERRED">
      We could compute the gradient of a moving window/filter. Compute deltas of points in the directions they will move,
      then compute the derivative based on that. Points will move along edges if on the boundary.
      Points in corners don't have compensation. Points on the "shifting" (not sliding) border likely have compensation.
    </p>

    <script type="module">
      import { Node, Path } from '../../chipper/dist/js/scenery/js/imports.js';
      import { RenderStack, RenderPathBoolean, RenderPath, RenderFromNode, PolygonFilterType, RenderDepthSort, RenderColor } from '../../chipper/dist/js/alpenglow/js/imports.js';
      import { Shape } from '../../chipper/dist/js/kite/js/imports.js';
      import dot from '../../chipper/dist/js/dot/js/dot.js';
      const v2 = dot.v2;
      const v3 = dot.v3;
      const v4 = dot.v4;
      const Matrix3 = dot.Matrix3;

      const getCheckerboard = type => {
        const width = 128;
        const height = width / 2;

        const dl = 10;

        const projectionMatrix = RenderDepthSort.getProjectionMatrix( 1, 100, -1, -1, 1, 1 );
        const rotationMatrix = Matrix3.rotationY( 0.1 ).timesMatrix( Matrix3.rotationX( 0 ) );
        const project = p => {

          // a rotation, for testing
          p = rotationMatrix.timesVector3( p.minus( v3( 0, 0, dl ) ) ).plus( v3( 0, 0, dl ) );

          const clip = projectionMatrix.timesVector4( v4( p.x, p.y, p.z, 1 ) );
          return v3( clip.x / clip.w, -clip.y / clip.w, clip.z / clip.w );
        };

        const polygons = [];

        const matrix = Matrix3.scaling( height ).timesMatrix( Matrix3.translation( 1, 0, 0 ) );

        const xSpan = 40;
        const y = -5;
        const zMax = 100;

        for ( let x = -xSpan; x < xSpan; x++ ) {
          for ( let z = 4; z < zMax; z++ ) {
            if ( ( x + z ) % 2 === 0 ) {
              continue;
            }
            const p0 = matrix.timesVector2( project( v3( x, y, z ) ).toVector2() );
            const p1 = matrix.timesVector2( project( v3( x + 1, y, z ) ).toVector2() );
            const p2 = matrix.timesVector2( project( v3( x + 1, y, z + 1 ) ).toVector2() );
            const p3 = matrix.timesVector2( project( v3( x, y, z + 1 ) ).toVector2() );

            polygons.push( [ p0, p1, p2, p3 ] );
          }
        }

        if ( type === 'svg' || type === 'canvas' || type === 'vello' ) {
          return window.getSceneryElement(
            new Node( {
              renderer: type,
              children: polygons.map( polygon => new Path( Shape.polygon( polygon ), { fill: 'black' } ) )
            } ),
            width, height, 'white', type
          );
        }
        else {
          const program = new RenderStack( [
            new RenderPathBoolean(
              new RenderPath( 'nonzero', polygons ),
              RenderFromNode.colorFrom( 'black' ),
              RenderFromNode.colorFrom( 'white' )
            )
          ] );

          return window.getRasterizedElement( program, width, height, {
            polygonFiltering: {
              box: PolygonFilterType.Box,
              bilinear: PolygonFilterType.Bilinear,
              mitchellNetravali: PolygonFilterType.MitchellNetravali
            }[ type ]
          } );
        }
      };

      const getSiemensStar = ( type, pointCount ) => {
        const width = 128;
        const height = 128;

        const center = v2( width / 2 + 0.15992094, height / 2 + 0.426296 );
        const radius = width * 0.49;

        const polygon = [];
        for ( let i = 0; i < pointCount; i++ ) {
          const angle0 = i * 2 * Math.PI / pointCount;
          const angle1 = ( i + 0.5 ) * 2 * Math.PI / pointCount;

          const p0 = v2( center.x + radius * Math.cos( angle0 ), center.y + radius * Math.sin( angle0 ) );
          const p1 = v2( center.x + radius * Math.cos( angle1 ), center.y + radius * Math.sin( angle1 ) );

          polygon.push( center );
          polygon.push( p0 );
          polygon.push( p1 );
        }

        if ( type === 'svg' || type === 'canvas' || type === 'vello' ) {
          return window.getSceneryElement(
            new Path( Shape.polygon( polygon ), { fill: 'black', renderer: type } ),
            width, height, 'white', type
          );
        }
        else if ( type === 'box' || type === 'bilinear' || type === 'mitchellNetravali' ) {
          const filtering = {
            box: PolygonFilterType.Box,
            bilinear: PolygonFilterType.Bilinear,
            mitchellNetravali: PolygonFilterType.MitchellNetravali
          }[ type ];

          const program = new RenderPathBoolean(
            new RenderPath( 'nonzero', [ polygon ] ),
            RenderFromNode.colorFrom( 'black' ),
            RenderFromNode.colorFrom( 'white' )
          );

          return window.getRasterizedElement( program, width, height, {
            polygonFiltering: filtering
          } );
        }
        else {
          throw new Error( 'unknown type' );
        }
      };

      const getFiltered = ( filter, multiplier ) => {
        const width = 150;
        const height = 150;

        const program = new RenderStack( [
          new RenderPathBoolean(
            new RenderPath( 'nonzero', [ [
              phet.dot.v2( 30, 30 ),
              phet.dot.v2( 120, 30 ),
              phet.dot.v2( 120, 120 ),
              phet.dot.v2( 30, 120 )
            ], [
              phet.dot.v2( 35, 35 ),
              phet.dot.v2( 45, 105 ),
              phet.dot.v2( 90, 90 ),
              phet.dot.v2( 105, 35 )
            ] ] ),
            RenderFromNode.colorFrom( 'black' ),
            RenderFromNode.colorFrom( 'white' )
          ),
          new RenderPathBoolean(
            new RenderPath( 'nonzero', [
              ...window.shapeToPolygons( Shape.regularPolygon( 20, 5 ).transformed( Matrix3.translation( 100, 100 ) ) )
            ] ),
            RenderFromNode.colorFrom( 'red' ),
            RenderColor.TRANSPARENT
          ),
          new RenderPathBoolean(
            new RenderPath( 'nonzero', [ [
              phet.dot.v2( 50, 50 ),
              phet.dot.v2( 45, 105 ),
              phet.dot.v2( 90, 90 )
            ] ] ),
            RenderFromNode.colorFrom( 'blue' ),
            RenderColor.TRANSPARENT
          )
        ] );

        return window.getRasterizedElement( program, width, height, {
          polygonFiltering: filter,
          polygonFilterWindowMultiplier: multiplier * window.devicePixelRatio
        } );
      };

      window.addDiagram( 'checkerboard-canvas', () => getCheckerboard( 'canvas' ) );
      window.addDiagram( 'checkerboard-svg', () => getCheckerboard( 'svg' ) );
      window.addDiagram( 'checkerboard-box', () => getCheckerboard( 'box' ) );
      window.addDiagram( 'checkerboard-bilinear', () => getCheckerboard( 'bilinear' ) );
      window.addDiagram( 'checkerboard-mitchell-netravali', () => getCheckerboard( 'mitchellNetravali' ) );

      window.addDiagram( 'siemens-canvas', () => getSiemensStar( 'canvas', 200 ) );
      window.addDiagram( 'siemens-svg', () => getSiemensStar( 'svg', 200 ) );
      window.addDiagram( 'siemens-box', () => getSiemensStar( 'box', 200 ) );
      window.addDiagram( 'siemens-bilinear', () => getSiemensStar( 'bilinear', 200 ) );
      window.addDiagram( 'siemens-mitchell-netravali', () => getSiemensStar( 'mitchellNetravali', 200 ) );

      window.addDiagram( 'blur-reference', () => getFiltered( PolygonFilterType.Box, 1 ) );
      window.addDiagram( 'blur-box', () => getFiltered( PolygonFilterType.Box, 10 ) );
      window.addDiagram( 'blur-bilinear', () => getFiltered( PolygonFilterType.Bilinear, 10 ) );
      window.addDiagram( 'blur-mitchell-netravali', () => getFiltered( PolygonFilterType.MitchellNetravali, 10 ) );
    </script>

    <h3 id="color-and-blending">Color &amp; Blending</h3>

    <p>
      Blending of colors is important to get right for correct visual results. There are multiple color spaces where
      blending can be done. Furthermore, anti-aliasing with correct blending will give a more accurate appearance.
    </p>

    <p>
      For example, in the above anti-aliasing examples, on many browsers the SVG/Canvas examples will show a "darkening"
      in areas where there is a lot of overlap. This is typically a result of blending in the sRGB color space, which
      is NOT linear.
    </p>

    <p class="TODO">Blending with/without linear conversion</p>

    <p class="TODO">Blending in different color spaces</p>

    <p class="TODO">Premultiplication section</p>

    <p class="TODO">Gamma correction notes</p>

    <p class="TODO">sRGB and Display P3 --- Note the Display P3 color matrices (we could not find those online)</p>

    <p class="TODO">
      Check that the Display P3 colors are side-by-side identical - maybe white point slight change? WE SHOULD check
      Chrome's conversions
    </p>

    <p class="TODO">Gamut Mapping</p>

    <p class="TODO">
      Better gamut mapping: <a href="https://bottosson.github.io/posts/gamutclipping/">https://bottosson.github.io/posts/gamutclipping/</a>
    </p>

    <p class="TODO">More documentation</p>

    <p class="TODO">
      Get oklch color space up and running, can do hue gradients then.
    </p>

    <h3 id="renderProgram">RenderProgram</h3>

    <p class="TODO">Documentation</p>

    <p class="TODO">
      NOTE: That the CAG process is essentially just simplifying into a different RenderStack (RenderUnion, because it
      is disjoint?) with each RenderableFace included. And our rasterizer is also just a RenderProgram transform, giving
      us a RenderableFace broken down to the pixel level. Note that we split everything except for gradients/depth at the
      first step, THEN we split gradients/depth. We could potentially generalize to different stages of splitting, OR
      we could force splitting all at once.
    </p>

    <p class="TODO">
      Allow more general computation, with conditionals, RenderPrograms that provide the x,y, Constant(n), all Vector4
      for now (based on our stack for things). Possibly, can we auto-differentiate RenderPrograms?
    </p>

    <p class="TODO">
      Generalized first-class rasterization: Implement gaussian blur / drop shadow, by executing an overfiltered copy,
      then combine? This would require a lot more legwork to do.
    </p>

    <h4 id="RenderColor">RenderColor</h4>

    <p>
      RenderColor displays a single solid color everywhere, and is a basic building-block for many other RenderPrograms.
    </p>

    <div class="example">
      <div id="RenderColor-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'RenderColor-example', () => {
        /*START*/
        const program = new RenderColor( new Vector4( 1, 0, 0, 1 ) );
        /*END*/
        return program;
      }, 128, 128 );
    </script>

    <p>
      Note that the default color space is <a href="https://en.wikipedia.org/wiki/SRGB">sRGB</a>. Additionally, the
      values are by default interpreted with
      <a href="https://en.wikipedia.org/wiki/Alpha_compositing#Straight_versus_premultiplied">premultiplied alpha</a>
      (also called associated alpha), so <code>0.5, 0, 0, 0.5</code> will represent a 50% transparent fully-red color.
    </p>

    <h4 id="RenderPathBoolean">RenderPathBoolean</h4>

    <p>
      RenderPathBoolean will display one RenderProgram "inside" the path, and another RenderProgram "outside" the path.
    </p>

    <div class="example">
      <div id="RenderPathBoolean-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'RenderPathBoolean-example', () => {
        /*START*/
        const program = new RenderPathBoolean(
          // The path. We have a "fill rule" of nonzero, which defines which sections
          // are considered inside. See https://en.wikipedia.org/wiki/Nonzero-rule
          new RenderPath( 'nonzero', [ [
            v2( 20, 20 ),
            v2( 90, 40 ),
            v2( 118, 118 ),
            v2( 50, 80 )
          ] ] ),

          // The "inside" RenderProgram
          new RenderColor( new Vector4( 1, 0, 0, 1 ) ),

          // The "outside" RenderProgram
          new RenderColor( new Vector4( 0.8, 0.8, 0.8, 1 ) )
        );
        /*END*/
        return program;
      }, 128, 128 );
    </script>

    <h4 id="RenderStack">RenderStack</h4>

    <p>
      RenderStack will apply normal compositing/blending to a list of RenderPrograms, where each RenderProgram in the
      list is drawn "on top" of all of the previous ones.
    </p>

    <div class="example">
      <div id="RenderStack-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'RenderStack-example', () => {
        /*START*/
        const program = new RenderStack( [
          // A constant background color
          new RenderColor( new Vector4( 0, 0, 0, 1 ) ),

          // Red diamond
          RenderPathBoolean.fromInside( // applies "transparent" to the "outside"
            new RenderPath( 'nonzero', [ [
              v2( 20, 20 ), v2( 90, 40 ), v2( 118, 118 ), v2( 50, 80 )
            ] ] ),
            new RenderColor( new Vector4( 1, 0, 0, 1 ) )
          ),

          // Green triangle
          RenderPathBoolean.fromInside(
            new RenderPath( 'nonzero', [ [
              v2( 10, 10 ), v2( 90, 10 ), v2( 10, 90 )
            ] ] ),
            new RenderColor( new Vector4( 0, 1, 0, 1 ) )
          ),

          // Semi-transparent white rectangle
          RenderPathBoolean.fromInside(
            new RenderPath( 'nonzero', [ [
              v2( 30, 30 ), v2( 110, 30 ), v2( 110, 80 ), v2( 30, 80 )
            ] ] ),
            new RenderColor( new Vector4( 0.7, 0.7, 0.7, 0.7 ) )
          )
        ] );
        /*END*/
        return program;
      }, 128, 128 );
    </script>

    <h4 id="RenderLinearBlend">RenderLinearBlend</h4>

    <p>
      RenderLinearBlend will interpolate between two different RenderPrograms based on the location. It will evaluate
      <code>clamp( dot( scaledNormal, point ) - offset, 0, 1 )</code>, and will linearly blend between the "zero"
      program (when the value is 0) and the "one" program (when the value is 1).
    </p>

    <p>
      It can be used in a standalone way, however it is primarily meant to be used when a <code>RenderLinearGradient</code>
      is split into each section between two gradient stops.
    </p>

    <div class="example">
      <div id="RenderLinearBlend-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'RenderLinearBlend-example', () => {
        /*START*/
        const program = new RenderLinearBlend(
          new Vector2( 1 / 128, 0 ), // scaledNormal
          0, // offset
          RenderLinearBlendAccuracy.Accurate,

          // "zero" RenderProgram
          new RenderColor( new Vector4( 1, 0, 0, 1 ) ),

          // "one" RenderProgram
          new RenderColor( new Vector4( 0, 0, 1, 1 ) )
        );
        /*END*/
        return program;
      }, 128, 128 );
    </script>

    <h4 id="RenderLinearGradient">RenderLinearGradient</h4>

    <p>
      RenderLinearGradient will display the typical linear gradient.
    </p>

    <div class="example">
      <div id="RenderLinearGradient-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'RenderLinearGradient-example', () => {
        /*START*/
        const program = new RenderLinearGradient(
          Matrix3.IDENTITY, // transform
          new Vector2( 0, 0 ), // start
          new Vector2( 50, 20 ), // end
          [
            new RenderGradientStop( 0, new RenderColor( new Vector4( 0, 0, 0, 1 ) ) ),
            new RenderGradientStop( 0.5, new RenderColor( new Vector4( 1, 0, 0, 1 ) ) ),
            new RenderGradientStop( 1, new RenderColor( new Vector4( 1, 1, 1, 1 ) ) )
          ],
          RenderExtend.Repeat, // Pad, Repeat, Reflect
          RenderLinearGradientAccuracy.SplitAccurate
        );
        /*END*/
        return program;
      }, 128, 128 );
    </script>

    <p class="TODO">
      NOTE: The shear cases are broken on splits, we can't just transform the points
    </p>

    <h4 id="RenderRadialBlend">RenderRadialBlend</h4>

    <p>
      RenderRadialBlend will interpolate between two different RenderPrograms based on the location. It will evaluate
      <code>clamp( ( averageFragmentRadius - radius0 ) / ( radius1 - radius0 ), 0, 1 )</code>, and will linearly blend
      between the "zero" program (when the value is 0) and the "one" program (when the value is 1).
    </p>

    <p>
      It can be used in a standalone way, however it is primarily meant to be used when a <code>RenderRadialGradient</code>
      is circular, and is split into each radial-linear partition.
    </p>

    <div class="example">
      <div id="RenderRadialBlend-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'RenderRadialBlend-example', () => {
        /*START*/
        const program = new RenderRadialBlend(
          Matrix3.translation( 64, 64 ), // transform
          0, // radius0,
          64, // radius1
          RenderRadialBlendAccuracy.Accurate,

          // "zero" RenderProgram
          new RenderColor( new Vector4( 1, 0, 0, 1 ) ),

          // "one" RenderProgram
          new RenderColor( new Vector4( 0, 0, 1, 1 ) )
        );
        /*END*/
        return program;
      }, 128, 128 );
    </script>

    <h4 id="RenderRadialGradient">RenderRadialGradient</h4>

    <p>
      RenderRadialGradient will display the typical radial gradient.
    </p>

    <div class="example">
      <div id="RenderRadialGradient-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'RenderRadialGradient-example', () => {
        /*START*/
        const program = new RenderRadialGradient(
          Matrix3.IDENTITY, // transform
          new Vector2( 0, 0 ), // start
          0, // startRadius
          new Vector2( 0, 0 ), // end
          64, // endRadius
          [
            new RenderGradientStop( 0, new RenderColor( new Vector4( 0, 0, 0, 1 ) ) ),
            new RenderGradientStop( 0.5, new RenderColor( new Vector4( 1, 0, 0, 1 ) ) ),
            new RenderGradientStop( 1, new RenderColor( new Vector4( 1, 1, 1, 1 ) ) )
          ],
          RenderExtend.Repeat, // Pad, Repeat, Reflect
          RenderRadialGradientAccuracy.SplitAccurate
        );
        /*END*/
        return program;
      }, 128, 128 );
    </script>

    <p class="TODO">The split "Reflect" extend type seems to be reversed from the desired behavior!</p>

    <p class="TODO">We need UnsplitCentroid to get more general conic gradients working, it should NOT split in those cases</p>

    <h4 id="RenderBlendCompose">RenderBlendCompose</h4>

    <p>
      RenderBlendCompose will blend/composite two RenderPrograms with a more general blending model, that takes in
      a Porter-Duff <a href="https://en.wikipedia.org/wiki/Alpha_compositing">compositing mode</a>, in addition to a
      <a href="https://en.wikipedia.org/wiki/Blend_modes">blend mode</a>.
    </p>

    <div class="example">
      <div id="RenderBlendCompose-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'RenderBlendCompose-example', () => {
        const size = 90;
        const padding = 5;
        const n0 = padding;
        const n1 = ( size - 2 * padding ) / 3 + padding;
        const n2 = 2 * ( size - 2 * padding ) / 3 + padding;
        const n3 = 3 * ( size - 2 * padding ) / 3 + padding;
        /*START*/
        const exampleCompositeModes = [
          // There are a few more modes, for other compositing situations
          RenderComposeType.Over,
          RenderComposeType.In,
          RenderComposeType.Out,
          RenderComposeType.Atop,
          RenderComposeType.Xor
        ];
        const program = new RenderStack(
          exampleCompositeModes.map( ( composeMode, i ) => {
            const x = i * size;
            return new RenderBlendCompose(
              composeMode,
              RenderBlendType.Normal,
              RenderPathBoolean.fromInside(
                RenderPath.fromBounds( new Bounds2( x + n0, n0, x + n2, n2 ) ),
                new RenderColor( new Vector4( 1, 0, 0, 1 ) )
              ),
              RenderPathBoolean.fromInside(
                RenderPath.fromBounds( new Bounds2( x + n1, n1, x + n3, n3 ) ),
                new RenderColor( new Vector4( 0, 0.8, 0, 1 ) )
              )
            );
          } )
        );
        /*END*/
        return program;
      }, 5 * 90, 90 );
    </script>

    <p class="TODO">Add blend type example, once text is easier, like https://learn.microsoft.com/en-us/windows/win32/direct2d/blend</p>

    <p class="TODO">Docs/demo for RenderColorSpaceConversion (and color conversions), RenderPremultiply/RenderUnpremultiply</p>
    <p class="TODO">Docs/demo for RenderImage</p>

    <p class="TODO">
      Images can use the splitting infrastructure. Split with pixels. For regions of filter support. Box filter single
      sample per square. Bilinear larger and overlapping and each has 4 samples. Mitchell-Netravali has 16 per. Need to
      potentially store the transform, for asymmetric shear etc. we split into filterable sections.
    </p>

    <p class="TODO">
      Mipmapping! Blend between adjacent mipmap levels (especially for perspective). Anisotropic for 3d, like
      <a href="https://en.wikipedia.org/wiki/Anisotropic_filtering#/media/File:MipMap_Example_STS101_Anisotropic.png">this example</a>.
      We'll want to mipmap "based on the area" if we aren't doing the "analytic" bits. So isotropic mipmap can look at the scale.
      We'll want to "bias" presumably, adjustably?
      We'll want to mipmap-blend the "extended" version (in each mipmap level computed, if non-power-of-2, it should be "padded" with the extended version for correct results)
      Mipmaps should work for any filter type
    </p>

    <p class="TODO">
      HOW are we handling Images? One atlas? How are we able to split things so this works?
      We could always just... determine the size, and create that many atlases?
    </p>

    <p class="TODO">Docs/demo for RenderAlpha</p>
    <p class="TODO">Docs/demo for RenderFilter</p>
    <p class="TODO">Docs/demo for RenderBarycentricBlend</p>
    <p class="TODO">Docs/demo for RenderBarycentricPerspectiveBlend</p>
    <p class="TODO">Docs/demo for RenderDepthSort / RenderPlanar</p>
    <p class="TODO">Docs/demo for RenderPhong / RenderLight / RenderNormalize</p>

    <h4 id="renderProgram-simplification">Simplification</h4>

    <p class="TODO">Documentation</p>

    <h4 id="renderProgram-execution">Execution</h4>

    <p>
      The software tree form of RenderPrograms can be directly executed. However it's better if we turn our RenderProgram
      into a series of instructions that can be executed in a more efficient way.
    </p>

    <p>
      We're able to output instructions (both in software as types, and on the GPU in a binary format) that operate in
      a simple stack-based fashion. We'll have a main stack, where vec4 values are pushed and popped. Instructions
      primarily either push content, or pop content then push more content (processing existing values). We're able to
      determine a bound on the stack size by analyzing the RenderProgram (normal visual blending won't cause stack
      issues, since we're able to blend each pair of colors before computing the next color).
    </p>

    <p>
      This is combined with a stack of instruction indices, to support function calls and return values, in addition to
      simple branching logic. It turns out all of the primitives we need can be done with "opaque jumps" (if the top of
      the stack is a fully-opaque value, jump to an instruction index) and function calls.
    </p>

    <h5>Inputs for Evaluation</h5>

    <p>
      <code>RenderEvaluationContext</code> represents the main inputs to evaluation, namely:
    </p>

    <ul>
      <li>Bounding box of affected area (typically clipped to pixel sizes)</li>
      <li>(optional) face data (<code>ClippableFace</code>, or other edge-clipped data on the GPU)</li>
      <li>(optional) area</li>
      <li>(optional) centroid</li>
    </ul>

    <h5>Direct Evaluation</h5>

    <p>
      <code>RenderProgram</code> (TS object) supports the direct evaluation by calling
      <code>.evaluate( context: RenderEvaluationContext )</code>.
    </p>

    <h5>Instruction Evaluation</h5>

    <p>
      <code>RenderProgram</code> has a method <code>.writeInstructions( instructions: RenderInstruction[] )</code> that
      will write out instruction objects (<code>RenderInstruction</code>) in a stream-like fashion.
    </p>

    <p>
      These can be evaluated with <code>RenderExecutor</code> in software (load the instructions, and then it can be
      executed many times with different contexts).
    </p>

    <h5>Binary Instruction Evaluation</h5>

    <p>
      <code>RenderInstruction</code> has a number of utilities, including the ability to convert a stream of
      instructions into a binary format. These can then be executed on the GPU with WGSL code.
    </p>

    <p>
      Instruction lists in the binary format are always suffixed with an exit instruction, so that we can have a
      solid block containing multiple instruction lists. During rasterization, we need to track the index of the start
      of a RenderProgram's instructions inside this list.
    </p>

    <h5>Instructions Demo</h5>

    <p>
      Edit the below code to see its form, and the object/binary instructions associated with it.
    </p>

    <div class="example">
      <div id="execution-instructions-example"></div>
    </div>

    <script type="module">
      /* eslint-disable no-undef */
      window.createRenderProgramSandbox( 'execution-instructions-example', () => {
        /*START*/
        const program = new RenderLinearGradient(
          Matrix3.IDENTITY, // transform
          new Vector2( 0, 0 ), // start
          new Vector2( 50, 20 ), // end
          [
            new RenderGradientStop( 0, new RenderColor( new Vector4( 0, 0, 0, 1 ) ) ),
            new RenderGradientStop( 0.5, new RenderColor( new Vector4( 1, 0, 0, 1 ) ) ),
            new RenderGradientStop( 1, new RenderColor( new Vector4( 1, 1, 1, 1 ) ) )
          ],
          RenderExtend.Repeat, // Pad, Repeat, Reflect
          RenderLinearGradientAccuracy.SplitAccurate
        );
        /*END*/
        return program;
      }, 128, 128, {
        showInstructions: true
      } );
    </script>


    <p class="TODO">
      Add "stack depth" getters to RenderProgram (both the main and instruction stacks), so we know what depth is needed.
      RenderPhong can use up a good amount of stack space (ambient/diffuse/specular/position/normal + direction/color for
      each light), BUT we really want to minimize the memory individual invocations/threads take up during execution.
      We can customize the stack sizes at shader creation time... maybe we can do pipeline-overloadable constants
      instead?
    </p>

    <p class="TODO">
      Consider separating out the RenderInstruction items into its own subdirectory. Potentially the logic items also.
    </p>

    <p class="TODO">
      Add error handling to detect if we blow past a stack?
    </p>

    <p class="TODO">
      Full unit tests to compare all of the versions. Flesh it out, fuzz it.
    </p>

    <p class="TODO">
      Detect if we run past a buffer, and set a flag so we can restart with a larger buffer? This will still cause a delay...
    </p>

    <p class="TODO">
      Document stack-based operations with stack-effect diagrams: "( before -- after )" (top of stack states).
    </p>

    <p class="TODO">
      If we have hashed RenderPrograms, deduplicate so we only write RenderProgram instructions for one.
    </p>

    <p>
      Note: RenderProgram instruction execution can be interrupted and saved, if we want to do so in the future.
    </p>

    <h3 id="WGSL">WGSL</h3>

    <p class="TODO">
      <a href="https://github.com/wgsl-analyzer/wgsl-analyzer">wgsl-analyzer</a> our non-minified output! We can
      potentially format output too. Can we have the analysis in JS, or can we run it independently? Currently capable
      in VSCode.
    </p>

    <p class="TODO">
      Bake in support for context loss handling.
    </p>

    <p class="TODO">
      Create a pattern so that we can easily pre-load shaders before they are used.
    </p>

    <p class="TODO">
      Check the WGSL/WebGPU spec for changes!
    </p>

    <p class="TODO">
      Get bindings from DualSnippet (parsed from the WGSL?) so we don't have to specify on ComputeShader creation.
    </p>

    <p class="TODO">
      Live WGSL sandbox with compute input/output (and all our existing WGSL included?)
    </p>

    <p class="TODO">
      Figure out casing. CamelCase is nice for types, how is snake_case treating us? The disconnect with TypeScript styles
      is tricky. We're adding parenthesis to conditional statements when we don't have to (that the minifier is not yet
      confident enough to detect/remove).
    </p>

    <h4 id="WGSL-snippets">Snippets</h4>

    <p class="TODO">Note DualSnippet. Note ComputeShader</p>

    <h4 id="WGSL-preprocessing">Preprocessing</h4>

    <p class="TODO">NOTE #ifdef/#ifndef/#else/#endif #import #option #bindings</p>

    <h4 id="WGSL-minification">Minification</h4>

    <p class="TODO">Note progress on minification. TEST WITH IT ON</p>

    <p class="TODO">Note chipper <code>node js/scripts/transpile.js --watch --skipMinifyWGSL</code></p>

    <h4 id="WGSL-mangling">Mangling</h4>

    <p class="TODO">
      Mangling needs to run on all of the shader code at once. We've implemented mangling for the Vello setup, but we
      need to implement it in the chipper transpiler.
    </p>

    <p class="TODO">
      How do we get this running with our more templated solution? Is mangling that required for our setup?
    </p>

    <h4 id="WGSL-algorithms">Algorithms</h4>

    <p class="TODO">
      Templates should be able to create variable names that are unique.
    </p>

    <p class="TODO">
      Read papers and books!
    </p>

    <p>
      Examples, see <a href="https://stoneberry.dev/docs/api/">Stoneberry API</a>, <a href="https://github.com/moderngpu/moderngpu">modernGPU</a>.
    </p>

    <p>
      <a href="https://developer.chrome.com/blog/new-in-webgpu-118/">WebGPU updates for Chrome</a>
    </p>

    <p>
      For overlap:
    </p>

    <ol>
      <li><a href="https://therealmjp.github.io/posts/breaking-down-barriers-part-1-whats-a-barrier/">Whats a Barrier?</a></li>
      <li><a href="https://therealmjp.github.io/posts/breaking-down-barriers-part-2-synchronizing-gpu-threads/">Synchronizing GPU Threads</a></li>
      <li><a href="https://therealmjp.github.io/posts/breaking-down-barriers-part-3-multiple-command-processors/">https://therealmjp.github.io/posts/breaking-down-barriers-part-3-multiple-command-processors/</a></li>
      <li><a href="https://therealmjp.github.io/posts/breaking-down-barriers-part-4-gpu-preemption/">https://therealmjp.github.io/posts/breaking-down-barriers-part-4-gpu-preemption/</a></li>
      <li><a href="https://therealmjp.github.io/posts/breaking-down-barriers-part-5-back-to-the-real-world/">https://therealmjp.github.io/posts/breaking-down-barriers-part-5-back-to-the-real-world/</a></li>
      <li><a href="https://therealmjp.github.io/posts/breaking-down-barriers-part-6-experimenting-with-overlap-and-preemption/">https://therealmjp.github.io/posts/breaking-down-barriers-part-6-experimenting-with-overlap-and-preemption/</a></li>
    </ol>

    <p class="TODO">
      IMPORTANT: uniform probably not helping us for the storage config case. Just use it as a storage buffer(!?)
    </p>

    <p class="TODO">
      TEST with the overlap case WITH my performance profiling. See if it reports "parallel" handling.
      PerformanceTesting.loopExpensiveMultiple().
      THEN profile it with PIX to see if our profiling matches PIX.
    </p>

    <p class="TODO">
      Can we get a pattern with BufferLogger/TimestampLogger that abstracts over how we're calling things? This would
      be nice, ESPECIALLY if we can factor in some of the "abstract things out" that Stoneberry can do.
    </p>

    <p class="TODO">
      A templating function multiply (for constants), that can replace with bit shifts where helpful?
    </p>

    <p class="TODO">
      Clearly note where combine() is allowed to be commutative and where it's not (in the templates).
      Better document templates.
    </p>

    <p class="TODO">
      Allow subtract() in addition to combine() in templates, there are some cases where it might be more efficient to
      compute (if that's allowed).
    </p>

    <p class="DEFERRED">
      Create parallel TS version of templates.
    </p>

    <p class="TODO">
      Create a map of what in WGSL are abstract/concrete/structure/composite/constructible/fixed-footprint/plain/atomic/storable types
    </p>

    <p class="TODO">
      Use <code>arrayLength</code> builtin, perhaps we can use it to range check more efficiently? This only sometimes
      works, if we have filled the buffer fully?
    </p>

    <p class="TODO">
      Check into <a href="https://github.com/greggman/webgpu-utils">https://github.com/greggman/webgpu-utils</a>,
      could it work for WGSL struct offsets?
      <a href="https://webgpufundamentals.org/webgpu/lessons/resources/wgsl-offset-computer.html#">Offset computer</a>
    </p>

    <p>
      Some good examples of primitives: <a href="https://github.com/fynv/webgpu_math/tree/master/client">https://github.com/fynv/webgpu_math/tree/master/client</a>
    </p>

    <p>
      Some demos: <a href="https://tellusim.com/webgpu/">https://tellusim.com/webgpu/</a>.
    </p>

    <p class="TODO">
      Use <a href="https://developer.mozilla.org/en-US/docs/Web/API/GPUDevice/createComputePipelineAsync">createComputePipelineAsync</a>
      to non-blockingly create the shaders?
    </p>

    <p class="TODO">
      Factor out all of the associated code to render things to a Canvas texture (e.g. blitshader).
    </p>

    <p class="TODO">
      Figure out buffer reuse to avoid zero-init cost and those issues.
    </p>

    <h4 id="WGSL-reduce">Reduce</h4>

    <p class="TODO">
      Performance test with the non-unrolled versions
    </p>

    <p>
      ModernGPU notes on grain size: By choosing an odd number for VT we avoid bank conflicts that would otherwise be incurred when re-ordering data between strided and thread orders. Within a warp, all banks (VT * tid + i) % 32 are accessed exactly once for each step i when VT is odd. If VT is a power-of-two, you can expect VT-way conflicts at each step.
    </p>

    <p>
      Check <a href="https://compute.toys/">https://compute.toys/</a> (ShaderToy for WebGPU) for potential examples.
    </p>

    <p>
      <a href="https://simonbyrne.github.io/notes/fastmath/">Beware fast-math</a>
    </p>

    <p>
      <a href="https://kieber-emmons.medium.com/optimizing-parallel-reduction-in-metal-for-apple-m1-8e8677b49b01">Metal Reduce</a>.
    </p>

    <p class="TODO">
      Can we early-exit from a workgroup?
    </p>

    <h4 id="WGSL-scan">Scan</h4>

    <p>
      <a href="https://kieber-emmons.medium.com/efficient-parallel-prefix-sum-in-metal-for-apple-m1-9e60b974d62">Metal Scan</a>.
      Levien links: <a href="https://raphlinus.github.io/gpu/2021/11/17/prefix-sum-portable.html">newer</a>, <a href="https://raphlinus.github.io/gpu/2020/04/30/prefix-sum.html">older</a>.
    </p>

    <h4 id="WGSL-radixSort">Radix Sort</h4>

    <p>
      <a href="https://kieber-emmons.medium.com/memory-bandwidth-optimized-parallel-radix-sort-in-metal-for-apple-m1-and-beyond-4f4590cfd5d3">Metal Radix Sort</a>.
    </p>

    <p>
      See <a href="https://github.com/fynv/webgpu_math/blob/master/client/radix_sort.js">example</a>, or
      <a href="https://www.reddit.com/r/GraphicsProgramming/comments/14c7gok/parallel_radix_sort_confusions_options/">reddit note</a>.
    </p>

    <h4 id="WGSL-mergeSort">Merge Sort</h4>

    <p>
      Might be possible, see <a href="https://moderngpu.github.io/mergesort.html">ModernGPU merge sort</a>.
    </p>

    <h4 id="WGSL-memory">Memory</h4>

    <p>
      See thoughts for <a href="https://github.com/linebender/vello/issues/366">Vello</a>.
    </p>

    <p class="TODO">
      Bump allocation with atomics
    </p>

    <p class="TODO">
      Have a buffer that gets flags set if we run out of memory, or run into various problematic issues. (Or unrelated
      things like intersection hit rate).
    </p>

    <h4 id="WGSL-rationals">Rationals</h4>

    <p class="TODO">
      WE NEED to keep around our initial coordinates, or store something like that initially. Because otherwise,
      comparing Q128 cross-multiply messes with our bit depth. We would need u64u64multto128, subtracti128, etc.
      NOTE: If it is only an issue with sorting things with the same end, perhaps we could sort with floats and would
      have enough precision?
    </p>

    <p class="TODO">
      Use Karatsuba multiplication to get rid of another multiply.
    </p>

    <p class="TODO">
      HOW CRAZY: If we allow representations of square roots, could we handle cubic bezier intersections precisely?
      Get exact bounds? probably not everything - augment with floating point (especially for atan2) for fast angle
      comparison? OR, what is the best way to compare angles? We can still compare slope, right?
    </p>

    <p>
      Reference for bithacks: <a href="https://graphics.stanford.edu/~seander/bithacks.html">https://graphics.stanford.edu/~seander/bithacks.html</a>.
    </p>

    <h4 id="WGSL-profiling">Profiling</h4>

    <p>
      Using PIX on Windows. See <a href="https://gist.github.com/Popov72/41f71cbf8d55f2cb8cae93f439eee347">https://gist.github.com/Popov72/41f71cbf8d55f2cb8cae93f439eee347</a>
    </p>

    <p>
      See GPUProfiling and strategies. See also <a href="https://github.com/mighdoll/alpenbench">alpenbench</a>.
    </p>

    <p>
      Try <a href="https://renderdoc.org/">RenderDoc</a>.
    </p>

    <p class="TODO">
      Look for cases where we should turn array-of-structures into structure-of-arrays (e.g. striding) for better
      memory access patterns.
    </p>

    <p>
      Note: <code>--enable-dawn-features=allow_unsafe_apis --enable-webgpu-developer-features</code> for when we're profiling. Or
      <code>open -a "Google Chrome Canary" --args --enable-dawn-features=allow_unsafe_apis --enable-webgpu-developer-features</code> on macOS.
    </p>

    <p>
      Can we profile on Metal (on macBook), see <a href="https://developer.apple.com/documentation/xcode/optimizing-gpu-performance">https://developer.apple.com/documentation/xcode/optimizing-gpu-performance</a>.
    </p>

    <p class="TODO">
      Optimize for MAD (multiply-add, one cycle).
    </p>

    <p>
      <a href="https://developer.nvidia.com/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-35-gpu-program-optimization">Performance tips in general</a>,
      <a href="https://developer.nvidia.com/blog/how-access-global-memory-efficiently-cuda-c-kernels/">Global memory efficiency</a>,
      <a href="https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/">Grid stride loops</a>,
      <a href="https://developer.nvidia.com/blog/the-peak-performance-analysis-method-for-optimizing-any-gpu-workload/">Performance analysis</a>,
      <a href="https://gpuopen.com/learn/optimizing-gpu-occupancy-resource-usage-large-thread-groups/">Optimizing occupancy</a>,
      <a href="https://www.kodeco.com/books/metal-by-tutorials/v3.0/chapters/32-best-practices">32 best practices</a>,
      <a href="https://developer.nvidia.com/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-35-gpu-program-optimization">GPU optimization</a>,
      <a href="https://developer.nvidia.com/gpugems/gpugems">GPU Gems 1</a>,
      <a href="https://developer.nvidia.com/gpugems/gpugems2">GPU Gems 2</a>,
      <a href="https://developer.nvidia.com/gpugems/gpugems3">GPU Gems 3</a>
    </p>

    <p class="TODO">
      WebGL2 if possible, see <a href="https://webgl2fundamentals.org/webgl/lessons/webgl-gpgpu.html">Compute guide</a>
    </p>

    <p class="TODO">
      Test out a bunch of performance hypotheses.
    </p>

    <h3 id="asyncSimulation">Async Simulation</h3>

    <p>
      For use in rapid prototyping and debugging WGSL-like structured code, we've created the ability to run code with
      a similar execution model to WGSL with async/await code in JS/TS.
    </p>

    <p>
      It uses async/await to simulate the execution model by:
    </p>

    <ul>
      <li>
        Running threads/invocations and workgroups in parallel, by awaiting every storage/workgroup read/write (or
        synchronization barrier).
      </li>
      <li>
        Blocking all progress on threads in a workgroup on a synchronization barrier until all threads have reached it.
      </li>
      <li>
        Recording all of the read/writes to storage/workgroup arrays (and which thread/workgroup they were set by),
        with logic on synchronization barriers. This allows detecting potential data races, uniformity issues,
        missing barriers, or other issues.
      </li>
      <li>
        Returning indeterminate values from out-of-bounds or un-initialized array accesses.
      </li>
    </ul>

    <p>
      In the model, typically <code>ParallelStorageArray</code>s are created, and then shaders are dispatched
      by running <code>ParallelExecutor</code>'s <code>dispatch()</code> method (with the dispatch size passed in).
      <code>ParallelExecutor</code>s are created with <code>ParallelKernel</code>, which is roughly equivalent to
      individual shaders. They will specify an async execute function, in addition to a way of creating workgroup-scoped
      values (in a statically-typed way). Workgroup-scoped values can be either atomics, or <code>ParallelWorkgroupArray</code>s.
    </p>

    <p>
      The execute function is given a reference to a context (<code>ParallelContext</code>) that will provide access to
      workgroup-scoped values and synchronization barriers (workgroupBarrier/storageBarrier) directly.
      It's also passed to storage/workgroup data read/writes, so that we can record the accesses and fail out assertions
      if certain data access pattersn are detected.
    </p>

    <p>
      <code>ParallelRaster</code> is an example of TypeScript code validating the model used for the raster-clipping
      process. <code>ParallelRasterSplitScan</code> is an example of a single shader in this model.
    </p>

    <h3 id="depthSort">Depth Sort</h3>

    <p>
      If we store data about what 3D plane each face is on (essentially assigning a depth to each 2d point), it's
      possible to analytically determine the exact divisions between sections where one face is in front of the other.
      For any given pair of planes, there is a 2d line in screen space that delineates the boundary between the two
      areas (the "depth sort line"). We'll use this to further split our polygons into disjoint sections where we have
      a total ordering of the planar faces (recall, Alpenglow stages will already have found us a section that is fully
      contained within the faces).
    </p>

    <p>
      This can be used to render 3d scenes, using sorting/splitting of the faces (instead of the normal technique of
      using a depth buffer). We will have a fully vector-friendly description of the 3d scene, down to an arbitrary
      precision!
    </p>

    <div class="row-fluid" style="margin-bottom: 15px;">
      <div class="span4 example">
        <div id="teapot-faces"></div>
        Faces
      </div>
      <div class="span4 example">
        <div id="teapot-normals"></div>
        Interpolated Normals
      </div>
      <div class="span4 example">
        <div id="teapot-phong"></div>
        Phong
      </div>
    </div>

    <script type="module">
      import { RenderColor, RenderDepthSort, RenderPathBoolean, RenderPath, RenderPlanar, Mesh, RenderLinearSRGBToSRGB, RenderNormalDebug, RenderPhong, RenderLight, RenderBarycentricPerspectiveBlend, RenderBarycentricPerspectiveBlendAccuracy, RenderNormalize } from '../../chipper/dist/js/alpenglow/js/imports.js';
      import dot from '../../chipper/dist/js/dot/js/dot.js';
      const v3 = dot.v3;
      const v4 = dot.v4;
      const Matrix3 = dot.Matrix3;
      const Matrix4 = dot.Matrix4;

      const getTeapot = ( shadeType, normalType ) => {
        const width = 200;
        const height = 200;

        const dl = 150;
        const projectionMatrix = RenderDepthSort.getProjectionMatrix( 1, 100, -1, -1, 1, 1 );
        const rotationMatrix = Matrix3.rotationY( 0 ).timesMatrix( Matrix3.rotationX( -0.5 ) );
        const project = p => {

          // a rotation, for testing
          p = rotationMatrix.timesVector3( p.minus( v3( 0, 0, dl ) ) ).plus( v3( 0, 0, dl ) );

          const clip = projectionMatrix.timesVector4( v4( p.x, p.y, p.z, 1 ) );
          return v3( clip.x / clip.w, -clip.y / clip.w, clip.z / clip.w );
        };

        const createTriangularMesh = ( mesh, matrix4 ) => {
          return mesh.faces.map( face => {
            const vertices = face.vertexIndices.map( i => mesh.vertices[ i ] ).reverse();
            const normals = face.normalIndices.map( i => mesh.normals[ i ] ).reverse();

            const transformedVertices = vertices.map( v => matrix4.timesVector3( v ) );
            const projectedVertices = transformedVertices.map( project );

            if ( projectedVertices[ 0 ].equals( projectedVertices[ 1 ] ) || projectedVertices[ 0 ].equals( projectedVertices[ 2 ] ) || projectedVertices[ 1 ].equals( projectedVertices[ 2 ] ) ) {
              return null;
            }

            const positionProgram = new RenderBarycentricPerspectiveBlend(
              projectedVertices[ 0 ], projectedVertices[ 1 ], projectedVertices[ 2 ],
              RenderBarycentricPerspectiveBlendAccuracy.Centroid,
              new RenderColor( transformedVertices[ 0 ].toVector4Zero() ),
              new RenderColor( transformedVertices[ 1 ].toVector4Zero() ),
              new RenderColor( transformedVertices[ 2 ].toVector4Zero() )
            );

            let normalProgram;
            if ( normalType === 'interpolated' ) {
              normalProgram = new RenderNormalize( new RenderBarycentricPerspectiveBlend(
                projectedVertices[ 0 ], projectedVertices[ 1 ], projectedVertices[ 2 ],
                RenderBarycentricPerspectiveBlendAccuracy.Centroid,
                new RenderColor( normals[ 0 ].toVector4Zero() ),
                new RenderColor( normals[ 1 ].toVector4Zero() ),
                new RenderColor( normals[ 2 ].toVector4Zero() )
              ) );
            }
            else if ( normalType === 'flat' ) {
              normalProgram = new RenderColor( normals[ 0 ].plus( normals[ 1 ] ).plus( normals[ 2 ] ).normalized().toVector4Zero() );
            }

            // const positionProgram = new RenderColor( transformedVertices[ 0 ].plus( transformedVertices[ 1 ] ).plus( transformedVertices[ 2 ] ).timesScalar( 1 / 3 ).toVector4() );

            let renderProgram;
            if ( shadeType === 'phong' ) {
              const ambientColorProgram = new RenderColor( v4( 0, 0, 0, 1 ) );
              const diffuseColorProgram = new RenderColor( v4( 1, 0.05, 0, 1 ) );
              const specularColorProgram = new RenderColor( v4( 0.5, 0.5, 0.5, 1 ) );
              renderProgram = new RenderPhong( 50, ambientColorProgram, diffuseColorProgram, specularColorProgram, positionProgram, normalProgram, [
                new RenderLight(
                  new RenderColor( v4( -2.0, 3.5, -2.0, 0 ).normalized() ),
                  new RenderColor( v4( 1, 1, 1, 1 ) )
                )
              ] );
            }
            else if ( shadeType === 'normals' ) {
              renderProgram = new RenderNormalDebug( normalProgram );
            }
            else if ( shadeType === 'random' ) {
              renderProgram = new RenderColor( v4( Math.random(), Math.random(), Math.random(), 1 ) );
            }

            return new RenderPlanar(
              RenderPathBoolean.fromInside( new RenderPath( 'nonzero', [ [
                projectedVertices[ 0 ].toVector2(), projectedVertices[ 1 ].toVector2(), projectedVertices[ 2 ].toVector2()
              ] ] ), renderProgram ),
              projectedVertices[ 0 ], projectedVertices[ 1 ], projectedVertices[ 2 ]
            );
          } ).filter( _.identity );
        };

        let program = new RenderDepthSort( [
          // eslint-disable-next-line no-undef
          ...createTriangularMesh( Mesh.loadOBJ( teapotOBJ )[ 0 ], Matrix4.translation( 0, 0, 150 ) )
        ] ).transformed( phet.dot.Matrix3.scaling( 170 * width / 256 ) ).transformed( phet.dot.Matrix3.translation( width / 2, height / 2 ) );
        if ( shadeType === 'phong' ) {
          program = new RenderLinearSRGBToSRGB( program );
        }

        return window.getRasterizedElement( program, width, height );
      };

      window.addDiagram( 'teapot-faces', () => getTeapot( 'random', 'flat' ) );
      window.addDiagram( 'teapot-normals', () => getTeapot( 'normals', 'interpolated' ) );
      window.addDiagram( 'teapot-phong', () => getTeapot( 'phong', 'interpolated' ) );

    </script>

    <p>
      Due to the total ordering of faces, we can actually <strong>trivially</strong> support multiple transparent
      objects correctly!
    </p>

    <div class="example">
      <div id="transparent-3d"></div>
    </div>

    <script type="module">
      import { RenderColor, RenderDepthSort, RenderPathBoolean, RenderPath, RenderPlanar, RenderLinearSRGBToSRGB, RenderPhong, RenderLight, RenderBarycentricPerspectiveBlend, RenderBarycentricPerspectiveBlendAccuracy, RenderNormalize } from '../../chipper/dist/js/alpenglow/js/imports.js';
      import dot from '../../chipper/dist/js/dot/js/dot.js';
      const v3 = dot.v3;
      const v4 = dot.v4;
      const Matrix3 = dot.Matrix3;

      const getTransparentSpheres = () => {
        const width = 128;
        const height = 128;

        const dl = 60;
        const projectionMatrix = RenderDepthSort.getProjectionMatrix( 1, 100, -1, -1, 1, 1 );
        const rotationMatrix = Matrix3.rotationY( 0 ).timesMatrix( Matrix3.rotationX( -0.5 ) );
        const project = p => {

          // a rotation, for testing
          p = rotationMatrix.timesVector3( p.minus( v3( 0, 0, dl ) ) ).plus( v3( 0, 0, dl ) );

          const clip = projectionMatrix.timesVector4( v4( p.x, p.y, p.z, 1 ) );
          return v3( clip.x / clip.w, -clip.y / clip.w, clip.z / clip.w );
        };
        const createSphere = ( center, radius, thetaDivisions, phiDivisions, alpha, diffuseColor ) => {
          const planars = [];

          for ( let i = 0; i < thetaDivisions; i++ ) {
            const theta0 = i / thetaDivisions * 2 * Math.PI;
            const theta1 = ( i + 1 ) / thetaDivisions * 2 * Math.PI;

            for ( let j = 0; j < phiDivisions; j++ ) {
              const phi0 = j / phiDivisions * Math.PI;
              const phi1 = ( j + 1 ) / phiDivisions * Math.PI;

              const p00 = v3(
                Math.sin( phi0 ) * Math.cos( theta0 ),
                Math.sin( phi0 ) * Math.sin( theta0 ),
                Math.cos( phi0 )
              );
              const p01 = v3(
                Math.sin( phi0 ) * Math.cos( theta1 ),
                Math.sin( phi0 ) * Math.sin( theta1 ),
                Math.cos( phi0 )
              );
              const p10 = v3(
                Math.sin( phi1 ) * Math.cos( theta0 ),
                Math.sin( phi1 ) * Math.sin( theta0 ),
                Math.cos( phi1 )
              );
              const p11 = v3(
                Math.sin( phi1 ) * Math.cos( theta1 ),
                Math.sin( phi1 ) * Math.sin( theta1 ),
                Math.cos( phi1 )
              );

              const tri = ( p0, p1, p2 ) => {

                const point0 = center.plus( p0.timesScalar( radius ) );
                const point1 = center.plus( p1.timesScalar( radius ) );
                const point2 = center.plus( p2.timesScalar( radius ) );

                const projected0 = project( point0 );
                const projected1 = project( point1 );
                const projected2 = project( point2 );

                const positionProgram = new RenderBarycentricPerspectiveBlend(
                  projected0, projected1, projected2,
                  RenderBarycentricPerspectiveBlendAccuracy.Centroid,
                  new RenderColor( point0.toVector4Zero() ),
                  new RenderColor( point1.toVector4Zero() ),
                  new RenderColor( point2.toVector4Zero() )
                );
                const normalProgram = new RenderNormalize( new RenderBarycentricPerspectiveBlend(
                  projected0, projected1, projected2,
                  RenderBarycentricPerspectiveBlendAccuracy.Centroid,
                  new RenderColor( p0.toVector4() ),
                  new RenderColor( p1.toVector4() ),
                  new RenderColor( p2.toVector4() )
                ) );

                const ambientColorProgram = new RenderColor( v4( 0, 0, 0, alpha ) );
                const diffuseColorProgram = new RenderColor( v4( diffuseColor.x, diffuseColor.y, diffuseColor.z, 0.01 ) );
                const specularColorProgram = new RenderColor( v4( 0.5, 0.5, 0.5, 0.01 ) );
                const program = new RenderPhong( 50, ambientColorProgram, diffuseColorProgram, specularColorProgram, positionProgram, normalProgram, [
                  new RenderLight(
                    new RenderColor( v4( -2.0, 3.5, -2.0, 0 ).normalized() ),
                    new RenderColor( v4( 1, 1, 1, 1 ) )
                  )
                ] );
                // const program = new RenderNormalDebug( normalProgram );

                return new RenderPlanar(
                  RenderPathBoolean.fromInside( new RenderPath( 'nonzero', [ [
                    projected0.toVector2(), projected1.toVector2(), projected2.toVector2()
                  ] ] ), program ),
                  projected0, projected1, projected2
                );
              };

              if ( !p00.equalsEpsilon( p01, 1e-6 ) && !p00.equalsEpsilon( p10, 1e-6 ) && !p01.equalsEpsilon( p10, 1e-6 ) ) {
                planars.push( tri( p00, p10, p01 ) );
              }
              if ( !p01.equalsEpsilon( p10, 1e-6 ) && !p01.equalsEpsilon( p11, 1e-6 ) && !p10.equalsEpsilon( p11, 1e-6 ) ) {
                planars.push( tri( p01, p10, p11 ) );
              }
            }
          }

          return planars;
        };

        const thetas = 16;
        const phis = 16;

        const program = new RenderLinearSRGBToSRGB( new RenderDepthSort( [
          ...createSphere( phet.dot.v3( 0, 0, dl ), 4, thetas, phis, 0.6, v3( 1, 0.05, 0 ) ),
          ...createSphere( phet.dot.v3( 2, 2, dl ), 4, thetas, phis, 1, v3( 0, 0.05, 1 ) ),
          ...createSphere( phet.dot.v3( 0, 4, dl ), 4, thetas, phis, 0.8, v3( 0, 1, 0.05 ) ),
          ...createSphere( phet.dot.v3( 4, 4, dl ), 4, thetas, phis, 0.4, v3( 0.8, 0.8, 0.8 ) )
        ] ) ).transformed( Matrix3.scaling( 4 * width ) ).transformed( Matrix3.translation( width / 2 - width / 8, height / 2 + height / 8 ) );

        return window.getRasterizedElement( program, width, height );
      };

      window.addDiagram( 'transparent-3d', () => getTransparentSpheres() );
    </script>

    <p class="TODO">
      Something wrong with normals in teapot example, set to 256x256 in demo.
    </p>

    <p class="TODO">
      Analytic perspective correction, see notes on paper --- looks like possible to integrate?
      <a href="https://en.wikipedia.org/wiki/Texture_mapping#Perspective_correctness">https://en.wikipedia.org/wiki/Texture_mapping#Perspective_correctness</a>
    </p>

    <p class="TODO">
      Show arbitrary graphics with 3d perspective:
      Quads in 3D (and putting vector graphics in them!) we'll just transform our graphics with perspective too?
      RenderPlanar with 3 points will work for quads just fine.
      Needs normal interpolation for quads.
      We can store the projective transform, to get exact gradients (in fact, we just need to do perspective correction).
    </p>

    <p class="TODO">
      Consider face consolidation after depth sort split! Should save a lot in rasterization?
    </p>

    <p class="TODO">
      Need to do breadth-first for our splitting in DepthSort, otherwise we're doing a lot of unnecessary splitting.
    </p>

    <p class="TODO">
      Checkerboard ground could be texture with analytic nearest image.
    </p>

    <p class="TODO">
      Planar getDepthSplit should check to see if the line goes through the bounds. We can skip expensive clipping a lot
    </p>

    <p class="TODO">
      Better name for RenderPlanar.
    </p>

    <p class="TODO">
      Near-far plane clipping in depth sort?
    </p>

    <p class="TODO">
      Stereographic/orthographic projection
    </p>

    <p class="TODO">
      For 3d how to plug shaders into RenderProgram?
    </p>

    <p class="TODO">
      Once we have RenderableFaces, we could split things up based on whatever shaders need to run - for instance, if
      we only can have certain shaders loaded, we can find the faces that use it? (multiple passes, for the different shaders?).
      If we're combining later anyway, why not skip the first (traced) consolidation?
      (Also for rasterization, we probably should NOT combine from separate tiles).
    </p>

    <h3 id="vectorCanvas">Vector Canvas</h3>

    <p class="TODO">
      Partially implemented in <code>VectorCanvas</code>. Basically it's possible to create a vector-accurate representation
      with our boolean operations. Any drawing operation will affect a (split) region, and it will update the RenderProgram in
      that region. We'll simplify all of those, then can consolidate areas with the same RenderProgram back together.
      For this to fully work nicely, we'd want to store the rational half edges permanently, and work in the rational
      space.
    </p>

    <p class="TODO">
      Radial and linear stuff in the vectorTest() uncommented can cause failures
    </p>

    <h3 id="testing">Testing</h3>

    <p class="TODO">
      More unit tests! Simplification. Clippers (fuzz, ensure we preserve area and are region-constricted). Compare to
      SVG/Canvas. Fuzz the rasterizer. Fuzz RenderPrograms.
    </p>

    <p class="TODO">
      Add assertions to make sure our faces have area that sums to the total!
    </p>

    <h2 id="stages">Stages</h2>

    <h3 id="stage-transforms">Transforms</h3>

    <p>
      Use a stack monoid setup to compute the nested transforms for every path. This isn't particularly required from
      Scenery (we CAN compute them CPU-side, but it uses up a lot of CPU time). However, we can ship over paths in an
      instanced fashion (e.g. font glyphs), and this stage would convert from the DAG to effectively a flat array of
      paths.
    </p>

    <p>
      NOTE: This will include perspective projection for 3D?
    </p>

    <h3 id="stage-subdivision">Subdivision</h3>

    <p>
      We'll want to convert our paths to polygons (a piecewise linear form). This could come before or after the
      transform step. Might need more code to do it after the transforms (logic needed to transform elliptical arcs,
      etc., but it would be more efficient.
    </p>

    <h3 id="stage-bounds">Bounds</h3>

    <p>
      We'll want the bounds of each path for later stages.
    </p>

    <h3 id="stage-tiling">Tiling</h3>

    <p>
      We'll subdivide the rendered area into tiles, and for each path we'll either skip it, fully include it, or clip it
      to the size of the tile.
    </p>

    <p>
      Certain potential final rasterization steps benefit from a guaranteed maximum tile size of path (e.g. if we're
      256x256, it would take 16 steps of binary subdivision to reach the pixel level).
    </p>

    <p>
      Tiling is also helpful to reduce the potential amount of cases for the later intersection step, AND with our
      integer transform, we'll be able to keep more precision for the CAG steps.
    </p>

    <p class="TODO">
      Note possibility: Just use tiling constraints in intersections and face holes. OTHERWISE we should be able to use
      the heterogeneous combination of tiles for other steps - but we might want to tile for rasterization too.
    </p>

    <h3 id="stage-integerTransform">Integer Transform</h3>

    <p>
      We'll scale up and transform our coordinate frame (for each tile) to integer coordinates, spaced out so that we're
      keeping about 20 bits of information for each coordinate. This will allow us to use rational numbers to compute
      the intersections between line segments (and to sort edges around each vertex) in an exact robust way, keeping our
      numerator and denominator within 64 bits each. Since the outputs will be signed, we'll want to put the origin
      approximately in the center of our "integer" coordinate frame.
    </p>

    <p>
      Our data will be in the <code>IntegerEdge</code> format, which essentially just stores the start point, end point,
      and the path ID.
    </p>

    <h3 id="stage-hilbertSort">Hilbert Sort</h3>

    <p>
      We'll sort the the edges using a higher-dimensional
      <a href="https://en.wikipedia.org/wiki/Hilbert_curve">Hilbert space-filling curve</a>, so that edges are somewhat
      spatially coherent (edges in a similar part of the list will likely have similar positions or sizes). This helps
      reduce the workload on the next step (intersection), since it would have theoretical O(n^2) performance.
      In practice, by having typical visual data AND sorting, we get a small fraction of that!
    </p>

    <p>
      This may be unnecessary for some workloads (where the edges provided are in a spatially coherent order due to
      the scene graph), however it's absolutely necessary for others (e.g. 3d meshes).
    </p>

    <p>
      This is inspired by the bulk loading of R-Trees (see <a href="https://dl.acm.org/doi/abs/10.1145/1963190.2025380">Four-dimensional hilbert curves for R-trees</a>, Haverkort et al. 2008).
    </p>

    <p>
      Planned to use a radix sort on GPU. Software is currently using a 6-dimensional Hilbert sort
      (centerX, centerY, minX, minY, maxX, maxY), but it's probably best to reduce that to a 4-dimensional sort.
    </p>

    <p class="TODO">
      Review paper for more insights. Potentially store Hilbert partials during the sort, OR just compute them to a given
      depth and store the result? (If we get something small however with a ton of dispersed edges... could CRATER
      performance).
    </p>

    <h3 id="stage-intersection">Intersection</h3>

    <p>
      We'll need to find all of the pairwise intersections between edges. In software, this is done by computing a
      binary tree of bounding boxes (where the Hilbert sort helps significantly). We can ignore the intersection between
      two subtrees whose bounding boxes do not intersect. Furthermore, if there are no horizontal lines in either
      subtree, we can allow the bounding boxes to "touch" horizontally (sharing a single line of intersection) without
      having any substantive pairwise intersection in edges, since we only care about internal intersections (those
      which aren't endpoint-to-endpoint).
    </p>

    <p>
      We'll store the intersections with their rational coordinates AND parametric value of intersection (also an
      exact rational) for each internal intersection within each of the edges.
    </p>

    <p>
      This intersection will also detect overlapping segments, and will find the endpoints that are internal to the
      other edge. Thus overlapping edges will thus be fully overlapping, and can be detected by future steps.
    </p>

    <p>
      Potentially plan to use bump allocation on the GPU, with a linked list for each edge (with atomic operations).
    </p>

    <p class="TODO">
      We are somewhat solving a "bounding box" intersection problem, but can we filter in a better way that solves the
      "line segment intersection" problem? When we split a line segment, remember it gets split into two smaller
      bounding boxes (not just splitting the large bounding box).
    </p>

    <p class="TODO">
      How inexpensively can we test 45-degree-oriented bounding boxes? This might be worth it
    </p>

    <p class="TODO">
      Flesh out that "alternative" plan in <code>BoundsIntersectionFilter</code>.
    </p>

    <p class="TODO">
      Can we store information about contiguous lists of segments with no intersections? Like, from guaranteed inputs,
      or from the same curved segment (when it's split into line segments) where we can guarantee no self-intersection?
    </p>

    <p class="TODO">
      Can we use homogeneous coordinates in intersections/etc. to avoid lots of division? equality or sort is hard? Read
      2005 Skala.
    </p>

    <h3 id="stage-split">Split</h3>

    <p>
      Each integer edge will have a list of internal intersections. We'll sort those intersections by their parametric
      value, and then we'll output a list of "rational" edges (using `RationalHalfEdge`) that make up each
      non-intersected interval of the original edge.
    </p>

    <p>
      We'll store the winding information for each path in this information. So if our edge in path X goes from A to B,
      we'll create two half-edges: A -> B (winding +1) and B -> A (winding -1), both marked for path X.
    </p>

    <p class="TODO">
      Look into merge sort for sorting the linked-list accumulated splits.
    </p>

    <p class="TODO">
      If we don't sort them, is it quadratic time? However, hopefully we won't have too many intersections, and that
      could potentially be acceptable? (Sort only if it's more than N splits in an edge?)
    </p>

    <h3 id="stage-edgeSort">Edge Sort</h3>

    <p>
      We'll sort our rational half-edges for the next stage (first by their starting point, then by their angle, then
      by their ID).
    </p>

    <p class="TODO">
      Perhaps use MergeSort instead of RadixSort on GPU? Radix sort might need a lot of bits, and it seems like we'd be
      doing 8 bits per pass?
    </p>

    <h3 id="stage-filterConnect">Filter &amp; Connect</h3>

    <p>
      There are two goals here:
    </p>

    <ul>
      <li>
        Combine otherwise identical overlapping half-edges together. Before this, each directional edge has one path
        that it's from, but now each half-edge will be from potentially multiple paths. We'll combine the winding
        contributions into a winding map (path => winding) for these cases. (NOTE: we're currently duplicating effort
        for the reverse edges here). We'll want to filter out duplicates (stream compaction on GPU).
      </li>
      <li>
        Connecting our half-edge structure together. Each half-edge already had a link to its "opposite" edge. However
        since we now have edges that are sorted by start THEN angle, we have effectively "ordered" all of the outgoing
        edges around each vertex, and thus we can store our "next" and "previous" half-edges if tracing
        counter-clockwise around the vertex. This will allow tracing of the edges in future steps.
      </li>
    </ul>

    <p>
      Notes: Monoid to scan edges, choose lowest index on each edge, propagate to the other edges. Presumably
      we should use half-edges for these data structures? (Should we be computing signed area in this pass?)
    </p>

    <h3 id="stage-boundaryTrace">Boundary Trace</h3>

    <p>
      We'll follow each half-edge until it loops back on itself. This will give us a boundary. It might be an
      "inner" or "outer" boundary. We can determine which it is by looking at the total signed area of the boundary
      (using the shoelace method). If it's positive, it's an inner boundary (is counter-clockwise), and if it's
      negative, it's an outer boundary (is clockwise). Outer boundaries are either (a) the outside of the bounding box
      or whatever region we have, or (b) a hole.
    </p>

    <p>
      Since we have signed area here, we can discard all edges with boundaries with zero area.
    </p>

    <p>
      On the GPU, we'll be able to use reduction techniques to make this efficient (like the linked list traversal).
    </p>

    <h3 id="stage-faceHoles">Face Holes</h3>

    <p>
      Each inner boundary determines a face. We need to compute which outer boundaries are holes, and for which faces.
      Once we figure out which boundaries are holes for which faces, we can forget about whether they are inner/outer
      and just combine all of the relevant boundaries together to represent the face.
    </p>

    <p>
      We'll first sort faces by their signed area. Then for each outer boundary, we'll take the point on it with the
      smallest x value (compatible with our edge sort above), and we'll scan for the smallest face that contains the
      point. We can filter a lot, ignoring faces smaller than the hole, faces whose bounding boxes don't fully
      (strictly) contain our hole, and we can take the smallest face that contains the point. Point-in-polygon testing
      is done with Dan Sunday's algorithm.
    </p>

    <p class="TODO">
      Look up what paper most of the filtering techniques are from!
    </p>

    <p>
      As part of this, we'll determine the "unbounded" outer face (the one that effectively contains the content OUTSIDE
      of the region we're rendering).
    </p>

    <h3 id="stage-windingMaps">Winding Maps</h3>

    <p>
      We need to compute the winding map for each face. The unbounded face contains zero winding, so we can start with
      it and find adjacent faces (through edges). Each time we find an adjacent edge with one face that has a winding
      map and one that doesn't, we can compute the winding map for the face that doesn't have one (based on the
      information in the edge and in the one face).
    </p>

    <h3 id="stage-renderProgramSimplification">RenderProgram Simplification</h3>

    <p>
      Our winding map for each face, combined with the winding rule for each path, gives us a boolean map (whether
      a path is included or not) for each face. In general these are sparse, so they will only mention the included
      faces. We can simplify the RenderProgram for each face by simplifying it with the path inclusion information
      (replacing each <code>RenderPathBoolean</code> with either the inside or outside RenderProgram), combined with
      simplification.
    </p>

    <p>
      We will precompute (possibly on the CPU) a replacement acceleration structure, since we'll have many primitives
      that will simplify sparse path inclusion significantly. Thus if we have 1000 paths, and 3 of them are included
      in a face, we can create a simplified version of that RenderProgram without having to do a full scan of the 1000
      items. See <code>RenderPathReplacer</code> for more details.
    </p>

    <p class="TODO">
      Write up RenderPathReplacer documentation.
    </p>

    <p>
      Now, many of the faces will have constant-valued RenderPrograms, which can be rendered much more efficiently!
      We won't have to do per-pixel blending at all in these cases.
    </p>

    <h3 id="stage-renderableFaceCreation">RenderableFace Creation</h3>

    <p>
      There now might be multiple faces that have equivalent RenderPrograms (especially those that are adjacent faces).
      Based on performance characteristics, we may want to do one of the following:
    </p>

    <dl>
      <dt>
        Keep the faces separate
      </dt>
      <dd>
        Straightforward, but we'll process more edges than needed.
      </dd>
      <dt>
        Combine adjacent equivalent faces (just delete edges)
      </dt>
      <dd>
        We can scan edges to find ones with equivalent faces on both sides. We can then discard these edges, and deliver
        edges out in the "unsorted edge" format (ideally edge-clipped) for future stages.
      </dd>
      <dt>
        Combine adjacent equivalent faces (trace edges, skip equivalent)
      </dt>
      <dd>
        If we instead trace edges, and while traversing we skip over edges that have equivalent faces, we'll generate
        polygonal data for each face. This will leave us with the best end-result, but might be more costly.
      </dd>
      <dt>
        Fully combine all equivalent faces
      </dt>
      <dd>
        This could be done with "unsorted edges" or traced. We'll get a full path for each RenderProgram, however
        depending on the rasterization method used, having two far-away small items in the same face could hurt
        performance.
      </dd>
    </dl>

    <p class="TODO">
      NOTE: This is better implemented by generating hashes for every simplified RenderProgram, so we can do quick
      comparisons. Find everywhere we are doing equality right now (probably somewhat inefficiently?).
      ONCE this is done, it will let us DAG RenderPrograms nicely on the CPU, if we store a hashmap of simplified
      programs? (Is that useful?)
    </p>

    <p class="TODO">
      Visuals/examples would be helpful here.
    </p>

    <h3 id="stage-splitPrograms">Split Programs</h3>

    <p>
      Certain types of RenderPrograms will cause their RenderableFace to be split into multiple RenderableFaces. For
      example, the <code>RenderDepthSort</code> for 3d meshes will be able to find exact split lines between different
      3d faces fully included in the RenderableFace. Additionally, for high quality output, gradients can split their
      faces so that gradient stop transitions are properly anti-aliased.
    </p>

    <h3 id="stage-rasterize">Rasterize</h3>

    <div class="example" id="rasterize-initial-demo-container" style="display: none;">
      <p style="text-align: left;">
        Below, Alpenglow's WebGPU raster-clipping is demonstrated. The top image is the "normal" rasterization,
        while the other images adjust the transparency/brightness of the pixels by which stage they were rasterized in
        (showing the binary subdivision of the rasterization, and the early-exit for parts of paths that are fully included).
      </p>
      <div id="rasterize-initial-demo"></div>
    </div>

    <script type="module">
      import { TestToCanvas, RenderColorSpace, RenderStack, RenderPathBoolean, Rasterize, RenderColor, RenderLinearBlend, RenderPath, RenderLinearBlendAccuracy } from '../../chipper/dist/js/alpenglow/js/imports.js';

      window.deviceContextPromise.then( async deviceContext => {
        const outputSize = 256;
        const rasterSize = Math.ceil( outputSize * window.devicePixelRatio );

        const clippableFace = TestToCanvas.getTestPath();

        const mainFace = clippableFace.getTransformed( phet.dot.Matrix3.scaling( 0.37 ) );
        const smallerFace = clippableFace.getTransformed( phet.dot.Matrix3.translation( 16, 165 ).timesMatrix( phet.dot.Matrix3.scaling( 0.15 ) ) );

        const clientSpace = RenderColorSpace.premultipliedLinearSRGB;

        const program = new RenderStack( [
          new RenderPathBoolean(
            RenderPath.fromBounds( new phet.dot.Bounds2( 0, 0, 128, 256 ) ),
            new RenderColor(
              new phet.dot.Vector4( 0, 0, 0, 1 )
            ).colorConverted( RenderColorSpace.sRGB, clientSpace ),
            new RenderColor(
              new phet.dot.Vector4( 1, 1, 1, 1 )
            ).colorConverted( RenderColorSpace.sRGB, clientSpace )
          ),
          RenderPathBoolean.fromInside(
            new RenderPath( 'nonzero', smallerFace.toPolygonalFace().polygons ),
            new RenderColor(
              new phet.dot.Vector4( 1, 1, 1, 1 )
            ).colorConverted( RenderColorSpace.sRGB, clientSpace )
          ),
          RenderPathBoolean.fromInside(
            new RenderPath( 'nonzero', mainFace.toPolygonalFace().polygons ),
            new RenderLinearBlend(
              new phet.dot.Vector2( 1 / 256, 0 ),
              0,
              RenderLinearBlendAccuracy.Accurate,
              new RenderColor( new phet.dot.Vector4( 1, 0, 0, 1 ) ).colorConverted( RenderColorSpace.sRGB, RenderColorSpace.premultipliedOklab ),
              new RenderColor( new phet.dot.Vector4( 0.5, 0, 1, 1 ) ).colorConverted( RenderColorSpace.sRGB, RenderColorSpace.premultipliedOklab )
            ).colorConverted( RenderColorSpace.premultipliedOklab, clientSpace )
          )
        ] ).transformed( phet.dot.Matrix3.scaling( rasterSize / 256 ) );

        if ( deviceContext ) {
          document.getElementById( 'rasterize-initial-demo-container' ).style.display = 'block';

          const createCanvas = async numStages => {
            const canvas = document.createElement( 'canvas' );
            canvas.width = rasterSize;
            canvas.height = rasterSize;
            canvas.style.width = `${outputSize}px`;
            canvas.style.height = `${outputSize}px`;
            canvas.style.margin = '0 20px';
            // canvas.style.imageRendering = 'pixelated';

            const context = deviceContext.getCanvasContext( canvas, 'srgb' );

            await Rasterize.hybridRasterize( program, deviceContext, context, new phet.dot.Bounds2( 0, 0, rasterSize, rasterSize ), 'srgb', {
              rasterClipperOptions: {
                numStages: numStages,
                bufferExponent: 15 // We can get away with 14 on double-pixels, but...
              }
            } );

            return canvas;
          };

          document.getElementById( 'rasterize-initial-demo' ).appendChild( await createCanvas( 16 ) );

          document.getElementById( 'rasterize-initial-demo' ).appendChild( document.createElement( 'br' ) );

          const transparencyDemoContainer = document.createElement( 'div' );
          transparencyDemoContainer.style.margin = '10px 20px';
          transparencyDemoContainer.style.display = 'inline-block';
          transparencyDemoContainer.style.position = 'relative';
          transparencyDemoContainer.style.width = `${outputSize}px`;
          transparencyDemoContainer.style.height = `${outputSize}px`;
          document.getElementById( 'rasterize-initial-demo' ).appendChild( transparencyDemoContainer );
          for ( let i = 16; i > 0; i-- ) {
            const canvas = await createCanvas( i );
            canvas.style.position = 'absolute';
            canvas.style.top = '0';
            canvas.style.left = '0';
            canvas.style.opacity = '10%';
            transparencyDemoContainer.appendChild( canvas );
          }

          const brightnessDemoContainer = document.createElement( 'div' );
          brightnessDemoContainer.style.margin = '10px 20px';
          brightnessDemoContainer.style.display = 'inline-block';
          brightnessDemoContainer.style.position = 'relative';
          brightnessDemoContainer.style.width = `${outputSize}px`;
          brightnessDemoContainer.style.height = `${outputSize}px`;
          document.getElementById( 'rasterize-initial-demo' ).appendChild( brightnessDemoContainer );
          for ( let i = 16; i > 0; i-- ) {
            const canvas = await createCanvas( i );
            canvas.style.position = 'absolute';
            canvas.style.top = '0';
            canvas.style.left = '0';
            canvas.style.filter = `contrast(0) brightness(${i * 10}%)`;
            brightnessDemoContainer.appendChild( canvas );
          }
        }
      } );
    </script>

    <p>
      We'll want to take the path representation for each RenderableFace, and determine the coverage of each pixel.
    </p>

    <p class="TODO">
      See if we should use something like Lucidchart, Mermaid is fighting us with font size and layout.
    </p>

    <pre class="mermaid">
flowchart TD

    classDef default font-size:16px

    classDef outputClass stroke:#a00, font-size:16px
    classDef inputClass stroke:#0a0, font-size:16px
    classDef hideClass fill:transparent, stroke:transparent

    subgraph inputs [" "]
        inputChunks["inputChunks<br>RasterChunk[]"]:::inputClass
        inputEdges["inputEdges<br>RasterEdge[]"]:::inputClass
    end
    class inputs hideClass

    inputChunks --> InitialChunk([InitialChunk])
    InitialChunk --> clippedChunks0

    subgraph clippedChunks [" "]
        clippedChunks0["clippedChunks (no area data)<br>RasterClippedChunk[]"]
        clippedChunks1["clippedChunks (partial data)<br>RasterClippedChunk[]"]
        clippedChunks2["clippedChunks (partial data)<br>RasterClippedChunk[]"]
        clippedChunks3["clippedChunks (FULL data)<br>RasterClippedChunk[]"]
    end

    inputChunks & inputEdges & clippedChunks0 --> InitialClip([InitialClip])
    InitialClip --> clippedChunks1 & reduces0 & edgeClips["edgeClips<br>RasterEdgeClip[]"]

    clippedChunks1 & reduces0 --> ChunkReduce1([ChunkReduce]) --> reduces1 & clippedChunks2

    clippedChunks2 & reduces1 --> ChunkReduce2([ChunkReduce]) --> reduces2 & clippedChunks3

    clippedChunks3 & edgeClips --> InitialEdgeReduce([InitialEdgeReduce]) --> edgeReduces0reduce

    edgeReduces0reduce --> SplitReduce1 --> edgeReduces0scan & edgeReduces1reduce

    edgeReduces1reduce --> SplitReduce2 --> edgeReduces1scan & edgeReduces2reduce

    reduces0["chunkReduces0<br>RasterChunkReduceQuad[]"]
    reduces1["chunkReduces1<br>RasterChunkReduceQuad[]"]
    reduces2["chunkReduces2<br>RasterChunkReduceQuad[]"]

    subgraph edgeCounts [" "]
        reducibleEdgeCount["reducibleEdgeCount<br>number"]:::outputClass
        completeEdgeCount["completeEdgeCount<br>number"]:::outputClass
    end
    class edgeCounts hideClass

    edgeReduces2reduce --> reducibleEdgeCount & completeEdgeCount

    clippedChunks3 & edgeReduces0scan & edgeReduces1scan & edgeReduces2reduce & edgeClips --> EdgeScan([EdgeScan])
    EdgeScan --> reducibleEdges0
    EdgeScan --> completeEdges
    EdgeScan --> chunkIndices["chunkIndices<br>number[]<br>Stores edge start/end indices<br>f[2*clippedChunkIndex]=edgeStartIndex<br>f[2*clippedChunkIndex+1]=edgeEndIndex"]

    chunkIndexMap & chunkIndices & reducibleEdgeCount & reducibleEdges0 --> EdgeIndexPatch([EdgeIndexPatch]) --> reducibleEdges1

    clippedChunks3 --> InitialSplitReduce --> splitReduces0reduce
    splitReduces0reduce --> SplitReduceX --> splitReduces0scan & splitReduces1reduce
    splitReduces1reduce --> SplitReduceY --> splitReduces1scan & splitReduces2

    subgraph splits [" "]
        InitialSplitReduce([InitialSplitReduce])

        subgraph splitReduces0 [" "]
            splitReduces0reduce["splitReduces0 (reduced)<br>RasterSplitReduceData[]"]
            splitReduces0scan["splitReduces0 (scanned)<br>RasterSplitReduceData[]"]
        end

        subgraph splitReduces1 [" "]
            splitReduces1reduce["splitReduces1 (reduced)<br>RasterSplitReduceData[]"]
            splitReduces1scan["splitReduces1 (scanned)<br>RasterSplitReduceData[]"]
        end

        splitReduces2["splitReduces2<br>RasterSplitReduceData[]"]

        SplitReduceX([SplitReduce])
        SplitReduceY([SplitReduce])
    end
    class splits hideClass

    subgraph chunkCounts [" "]
        reducibleChunkCount["reducibleChunkCount<br>number"]:::outputClass
        completeChunkCount["completeChunkCount<br>number"]:::outputClass
    end
    class chunkCounts hideClass

    splitReduces2 --> reducibleChunkCount & completeChunkCount

    splitReduces2 & splitReduces1scan & splitReduces0scan & clippedChunks3 --> SplitScan([SplitScan])
    SplitScan --> reducibleChunks0
    SplitScan --> completeChunks0
    SplitScan --> chunkIndexMap["chunkIndexMap<br>number[]<br>f[clippedChunkIndex]=outputChunkIndex"]

    reducibleChunks0 & completeChunks0 & chunkIndexMap & chunkIndices & clippedChunks3 --> ChunkIndexPatch([ChunkIndexPatch])
    ChunkIndexPatch --> reducibleChunks1 & completeChunks1

    subgraph edges [" "]
        subgraph edgeReduces0 [" "]
            edgeReduces0reduce["edgeReduces0 (reduced)<br>RasterSplitReduceData[]"]
            edgeReduces0scan["edgeReduces0 (scanned)<br>RasterSplitReduceData[]"]
        end

        SplitReduce1([SplitReduce])

        subgraph edgeReduces1 [" "]
            edgeReduces1reduce["edgeReduces1 (reduced)<br>RasterSplitReduceData[]"]
            edgeReduces1scan["edgeReduces1 (scanned)<br>RasterSplitReduceData[]"]
        end

        SplitReduce2([SplitReduce])

        edgeReduces2reduce["edgeReduces2 (reduced)<br>RasterSplitReduceData[]"]
    end
    class edges hideClass

    subgraph outputEdges [" "]
        subgraph reducibleEdges [" "]
            reducibleEdges0["reducibleEdges (unmapped)<br>RasterEdge[]"]
            reducibleEdges1["reducibleEdges<br>RasterEdge[]"]:::outputClass
        end

        completeEdges["completeEdges<br>RasterCompleteEdge[]"]:::outputClass
    end
    class outputEdges hideClass

    subgraph reducibleChunks [" "]
        reducibleChunks0["reducibleChunks (no indices)<br>RasterChunk[]"]:::outputClass
        reducibleChunks1["reducibleChunks<br>RasterChunk[]"]:::outputClass
    end

    subgraph completeChunks [" "]
        completeChunks0["completeChunks (no indices)<br>RasterCompleteChunk[]"]
        completeChunks1["completeChunks<br>RasterCompleteChunk[]"]
    end

%%    subgraph outputs [" "]
%%        reducibleEdgeCount
%%        completeEdgeCount
%%        reducibleChunkCount
%%        completeChunkCount
%%        reducibleEdges1
%%        completeEdges
%%        reducibleChunks1
%%        completeChunks1
%%    end
%%    style outputs fill:transparent,stroke:transparent
    </pre>

    <p class="TODO">
      Customizable execution instruction limits, error out if past a certain level. This might be what is killing performance.
    </p>

    <p class="TODO">
      Read RAVG/Massive/Vello again, might switch to a technique more like that.
    </p>

    <p class="TODO">
      See if out-of-bounds writes are wrecking our correctness. They can scribble anywhere in the binding?
    </p>

    <p class="TODO">
      Restructure Parallel code handling so that out-of-bounds writes result in failures.
    </p>

    <p class="TODO">
      Can we combine all of the reduces into one buffer?
    </p>

    <p class="TODO">
      Can we combine our complete chunks and complete edges into one buffer? We are exporting to a bunch of other
      buffers currently? Or are we reusing it? Perhaps use atomics to store what is used/freed, and GC?
    </p>

    <p class="TODO">
      Try different workgroup sizes, see if it's better (especially when we can rake things)
    </p>

    <p>
      Track <a href="https://github.com/googlefonts/gpu-path-rendering-paper">https://github.com/googlefonts/gpu-path-rendering-paper</a>
    </p>

    <p class="TODO">
      Gamut mapping in WGSL seems to not be working.
    </p>

    <p class="TODO">
      Run a queue encoder for every tile independently?
    </p>

    <p class="TODO">
      Measure workgroup execution order on GPUs to see if we can schedule asymmetric (large) load workgroups first somehow.
    </p>

    <p class="TODO">
      Test better accumulation than our atomics strategy?
    </p>

    <p class="TODO">
      Analyze with GPT-4 for bug detection?
    </p>

    <p class="TODO">
      Create a "performance" section, to note things. Prefer Firefox for profiling CPU currently. Convert things to Rust
      and use WGPU to get better GPU profiling? (Or if we can profile Metal using the debug tools, that could help).
      Look into <a href="https://github.com/takahirox/webgpu-devtools">webgpu-devtools</a>. But for now, we can use FPS
      tests.
    </p>

    <p class="TODO">
      THERE IS SOMETHING WRONG with RasterClipper's completed edge output. It's bugging up actual centroid computation.
      Create assertions on the "parallel" side for this to track it down.
      --- This disappeared?!?
    </p>

    <p class="TODO">
      IMPORTANT! Our resulting edge-clipped counts should be cyclic, right? Only use 2 bits per count!!
      They should wrap around or accumulate as long as we do arithmetic mod 4.
      Right now we're taking up 4x i32 for this, and that's (a) excessive, (b) killing performance, and (c) reducing
      the size of our potential workgroups.
    </p>

    <p class="TODO">
      Modify our approach to grid-clip (2 levels?) - 256x256 tile can be done with two successive 16x16 grid clips.
    </p>

    <p class="TODO">
      There are graphical artifacts on <code>rasterTest()</code>. Assert that each stage is area-preserving
      (in parallel software first, then in hardware). Perhaps fuzz too.
    </p>

    <p class="TODO">
      Is indirect dispatch killing performance?
    </p>

    <p class="TODO">
      Better handle "constant" RenderPrograms, we can exit immediately!
    </p>

    <p class="TODO">
      See if we can change flags around our uniform config buffer?
    </p>

    <p class="TODO">
      Is memory bandwidth (and the number of dispatches with memory reads/writes) killing performance?
    </p>

    <p class="TODO">
      Performance seems to be very affected by the buffer sizes. Modify things so that we're working within the same
      buffer? I recall seeing a source saying they handle their own memory within a large buffer, instead of multiple
      buffers? See <a href="https://developer.nvidia.com/vulkan-memory-management">info</a>. Sub-allocation
      could be really efficient? How can we make sure our reads/writes are to the same area? Examine Vello approaches.
    </p>

    <p class="TODO">
      Alternative approaches, e.g. workgroup-per-initial-chunk? RenderProgram evaluation needs accurate edges
      unfortunately, and can use them in a linear way. NOTE: Maybe we can do a more efficient approach for the constant
      faces? (For instance, if we take the signed area of each edge, and accumulate that times the color, we do not
      have to do any cross-workgroup computation, and it's even more parallel). That does NOT work for RenderImage,
      or things where we really need the concept of "centroid" or face. We can't split up the centroid with that, since
      we need the full area in the first place to compute with (so we'd have to have the input area for faces?) - that
      is technically possible.
    </p>

    <p class="TODO">
      For RasterClipper approach, consider pipeline-overridable constants to change the reduce behavior for the last level.
    </p>

    <p class="TODO">
      Measure RasterClipper progression of chunk/edge counts every stage.
    </p>

    <p class="TODO">
      Raking and other better primitives in raster-clip!
    </p>

    <p class="TODO">
      Document the approaches here.
    </p>

    <p class="TODO">
      Check how will reduced precision affect centroid computations? Area also?
    </p>

    <p class="TODO">
      Add mermaid chart here. Add accumulate and to_texture steps. Add update_config/uniform step (before edge index
      patch). Potentially put config buffer in.
    </p>

    <p class="TODO">
      Show which parts finish in which stages, if we stick to that?
    </p>

    <p class="TODO">
      Can use different techniques for different classes of rasterization. One is constant/variable/centroid face
      needed. Other is quantity of edges
    </p>

    <p class="TODO">
      Note "9/4 worst case ratio for quad-clip grid-clip tiling"
    </p>

    <p class="TODO">
      Consider "CombinedRaster" like split? So we can avoid expensive mapping. Does this actually save us anything?
      It really only helps on the CPU?
    </p>

    <p class="TODO">
      Consider how we could split the raster-accumulate up based on what textures are needed (some passes run with some
      textures, other passes run with others).
    </p>

    <p class="DEFERRED">
      Use frames to split this left side!
    </p>

    <!-- DO NOT PLACE THINGS UNDER HERE -->

    <script type="module">
      import mermaid from '../../sherpa/mermaid/mermaid.esm.min.mjs'; // eslint-disable-line default-import-match-filename
      mermaid.initialize( { startOnLoad: true } );
    </script>

  </div>
  <div class="span2"></div>
</div>

</body>
</html>
